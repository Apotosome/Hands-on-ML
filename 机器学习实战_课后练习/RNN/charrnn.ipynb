{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c3f6219",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T17:18:01.627808Z",
     "iopub.status.busy": "2022-04-11T17:18:01.627048Z",
     "iopub.status.idle": "2022-04-11T17:18:07.607156Z",
     "shell.execute_reply": "2022-04-11T17:18:07.606142Z",
     "shell.execute_reply.started": "2022-04-11T17:16:23.078876Z"
    },
    "papermill": {
     "duration": 6.030298,
     "end_time": "2022-04-11T17:18:07.607329",
     "exception": false,
     "start_time": "2022-04-11T17:18:01.577031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def initialization(seed=42):\n",
    "    keras.backend.clear_session()\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a20640b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T17:18:07.693772Z",
     "iopub.status.busy": "2022-04-11T17:18:07.692857Z",
     "iopub.status.idle": "2022-04-11T17:18:07.695303Z",
     "shell.execute_reply": "2022-04-11T17:18:07.694707Z",
     "shell.execute_reply.started": "2022-04-11T17:16:28.979454Z"
    },
    "papermill": {
     "duration": 0.046469,
     "end_time": "2022-04-11T17:18:07.695424",
     "exception": false,
     "start_time": "2022-04-11T17:18:07.648955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib import font_manager\n",
    "my_font = font_manager.FontProperties(fname='./Fonts/SourceHanSerifSC-Medium.otf', size=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288dbab2",
   "metadata": {
    "papermill": {
     "duration": 0.038166,
     "end_time": "2022-04-11T17:18:07.773412",
     "exception": false,
     "start_time": "2022-04-11T17:18:07.735246",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 使用Character RNN生成莎士比亚风格的文本"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472d5c1b",
   "metadata": {
    "heading_collapsed": true,
    "papermill": {
     "duration": 0.036835,
     "end_time": "2022-04-11T17:18:07.847757",
     "exception": false,
     "start_time": "2022-04-11T17:18:07.810922",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 创建训练数据集 Creating the Training Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e81fe6",
   "metadata": {
    "hidden": true,
    "papermill": {
     "duration": 0.037577,
     "end_time": "2022-04-11T17:18:07.924142",
     "exception": false,
     "start_time": "2022-04-11T17:18:07.886565",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1. 使用`Keras`的`get_file()`函数，从项目中下载所有莎士比亚的作品"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1207a91e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T17:18:08.004513Z",
     "iopub.status.busy": "2022-04-11T17:18:08.003640Z",
     "iopub.status.idle": "2022-04-11T17:18:08.590269Z",
     "shell.execute_reply": "2022-04-11T17:18:08.590704Z",
     "shell.execute_reply.started": "2022-04-11T17:16:28.986024Z"
    },
    "hidden": true,
    "papermill": {
     "duration": 0.629265,
     "end_time": "2022-04-11T17:18:08.590874",
     "exception": false,
     "start_time": "2022-04-11T17:18:07.961609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
      "1122304/1115394 [==============================] - 0s 0us/step\n",
      "1130496/1115394 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "shakespeare_url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
    "filepath = keras.utils.get_file(\"shakespeare.txt\", shakespeare_url)\n",
    "\n",
    "with open(filepath) as f:\n",
    "    shakespeare_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52207d51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T17:18:08.673262Z",
     "iopub.status.busy": "2022-04-11T17:18:08.672593Z",
     "iopub.status.idle": "2022-04-11T17:18:08.675380Z",
     "shell.execute_reply": "2022-04-11T17:18:08.675786Z",
     "shell.execute_reply.started": "2022-04-11T17:16:29.850123Z"
    },
    "hidden": true,
    "papermill": {
     "duration": 0.045289,
     "end_time": "2022-04-11T17:18:08.675945",
     "exception": false,
     "start_time": "2022-04-11T17:18:08.630656",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(shakespeare_text[:148])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb1f7707",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T17:18:08.755741Z",
     "iopub.status.busy": "2022-04-11T17:18:08.754979Z",
     "iopub.status.idle": "2022-04-11T17:18:08.771581Z",
     "shell.execute_reply": "2022-04-11T17:18:08.772043Z",
     "shell.execute_reply.started": "2022-04-11T17:16:29.857862Z"
    },
    "hidden": true,
    "papermill": {
     "duration": 0.057756,
     "end_time": "2022-04-11T17:18:08.772161",
     "exception": false,
     "start_time": "2022-04-11T17:18:08.714405",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n !$&',-.3:;?abcdefghijklmnopqrstuvwxyz\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join(sorted(set(shakespeare_text.lower())))   # 显示文本中出现的所有字符"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e66bdf6",
   "metadata": {
    "hidden": true,
    "papermill": {
     "duration": 0.038368,
     "end_time": "2022-04-11T17:18:08.849535",
     "exception": false,
     "start_time": "2022-04-11T17:18:08.811167",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "2. 将每个字符编码为一个整数。\n",
    "    - 创建一个自定义预处理层，\n",
    "    - 或使用`Keras`的`Tokenizer`会更加简单。\n",
    "    \n",
    "    > **tf.keras.preprocessing.text.Tokenizer**\n",
    "    > ```python   \n",
    "        tf.keras.preprocessing.text.Tokenizer(\n",
    "            num_words=None,\n",
    "            filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',  # 过滤: 不包含 '\n",
    "            lower=True,   # 是否转化为小写\n",
    "            split=' ',\n",
    "            char_level=False,   # true: 每个字符都将被视为一个标记\n",
    "            oov_token=None,\n",
    "            document_count=0,\n",
    "            **kwargs\n",
    "        )\n",
    "    > ```   \n",
    "    > \n",
    "    > 默认情况下，所有标点符号都被删除，将文本转换为空格分隔的单词序列（单词可能包括 ' 字符）。然后将这些序列拆分为标记列表。然后它们将被索引或矢量化。\n",
    "    0 是一个保留索引，不会分配给任何单词。\n",
    "    >\n",
    "    > `fit_on_texts(texts)` : 根据文本列表更新内部词汇表\n",
    "    >\n",
    "    > `fit_on_sequences(texts)` : 根据序列列表更新内部词汇表\n",
    "    >\n",
    "    > `get_config()` : 根据文本列表更新内部词汇表"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43836f9d",
   "metadata": {
    "hidden": true,
    "papermill": {
     "duration": 0.038823,
     "end_time": "2022-04-11T17:18:08.927028",
     "exception": false,
     "start_time": "2022-04-11T17:18:08.888205",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- 首先，将一个将`tokenizer`拟合到文本：`tokenizer`能从文本中发现所有的字符，并将所有字符映射到不同的字符ID，**映射从1开始**.\n",
    "- 设置`char_level=True`，以得到**字符级别的编码**，而不是默认的单词级别的编码。这个`tokenizer`默认**将所有文本转换成了小写**（如果不想这样，可以设置`lower=False`）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68268101",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T17:18:09.037717Z",
     "iopub.status.busy": "2022-04-11T17:18:09.032675Z",
     "iopub.status.idle": "2022-04-11T17:18:10.379755Z",
     "shell.execute_reply": "2022-04-11T17:18:10.379221Z",
     "shell.execute_reply.started": "2022-04-11T17:16:29.882006Z"
    },
    "hidden": true,
    "papermill": {
     "duration": 1.413763,
     "end_time": "2022-04-11T17:18:10.379898",
     "exception": false,
     "start_time": "2022-04-11T17:18:08.966135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = keras.preprocessing.text.Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts(shakespeare_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b2bd3c",
   "metadata": {
    "hidden": true,
    "papermill": {
     "duration": 0.038634,
     "end_time": "2022-04-11T17:18:10.458621",
     "exception": false,
     "start_time": "2022-04-11T17:18:10.419987",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- 现在`tokenizer`可以将一整句（或句子列表）编码为`字符ID列表`，这可以告诉我们文本中有多少个独立的字符，以及总字符数."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62adb170",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T17:18:10.541498Z",
     "iopub.status.busy": "2022-04-11T17:18:10.540900Z",
     "iopub.status.idle": "2022-04-11T17:18:10.543467Z",
     "shell.execute_reply": "2022-04-11T17:18:10.543869Z",
     "shell.execute_reply.started": "2022-04-11T17:16:31.291448Z"
    },
    "hidden": true,
    "papermill": {
     "duration": 0.046605,
     "end_time": "2022-04-11T17:18:10.544003",
     "exception": false,
     "start_time": "2022-04-11T17:18:10.497398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[20, 6, 9, 8, 3]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences(['First'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d678bdf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T17:18:10.626673Z",
     "iopub.status.busy": "2022-04-11T17:18:10.625762Z",
     "iopub.status.idle": "2022-04-11T17:18:10.629623Z",
     "shell.execute_reply": "2022-04-11T17:18:10.629220Z",
     "shell.execute_reply.started": "2022-04-11T17:16:31.300935Z"
    },
    "hidden": true,
    "papermill": {
     "duration": 0.046906,
     "end_time": "2022-04-11T17:18:10.629725",
     "exception": false,
     "start_time": "2022-04-11T17:18:10.582819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['f i r s t']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.sequences_to_texts([[20, 6, 9, 8, 3]])   # 不区分大小写"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c063befb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T17:18:10.730627Z",
     "iopub.status.busy": "2022-04-11T17:18:10.728745Z",
     "iopub.status.idle": "2022-04-11T17:18:10.734370Z",
     "shell.execute_reply": "2022-04-11T17:18:10.733797Z",
     "shell.execute_reply.started": "2022-04-11T17:16:31.309684Z"
    },
    "hidden": true,
    "papermill": {
     "duration": 0.053455,
     "end_time": "2022-04-11T17:18:10.734520",
     "exception": false,
     "start_time": "2022-04-11T17:18:10.681065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 1,\n",
       " 'e': 2,\n",
       " 't': 3,\n",
       " 'o': 4,\n",
       " 'a': 5,\n",
       " 'i': 6,\n",
       " 'h': 7,\n",
       " 's': 8,\n",
       " 'r': 9,\n",
       " 'n': 10,\n",
       " '\\n': 11,\n",
       " 'l': 12,\n",
       " 'd': 13,\n",
       " 'u': 14,\n",
       " 'm': 15,\n",
       " 'y': 16,\n",
       " 'w': 17,\n",
       " ',': 18,\n",
       " 'c': 19,\n",
       " 'f': 20,\n",
       " 'g': 21,\n",
       " 'b': 22,\n",
       " 'p': 23,\n",
       " ':': 24,\n",
       " 'k': 25,\n",
       " 'v': 26,\n",
       " '.': 27,\n",
       " \"'\": 28,\n",
       " ';': 29,\n",
       " '?': 30,\n",
       " '!': 31,\n",
       " '-': 32,\n",
       " 'j': 33,\n",
       " 'q': 34,\n",
       " 'x': 35,\n",
       " 'z': 36,\n",
       " '3': 37,\n",
       " '&': 38,\n",
       " '$': 39}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 列出字符索引\n",
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed3d69f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T17:18:10.824995Z",
     "iopub.status.busy": "2022-04-11T17:18:10.824247Z",
     "iopub.status.idle": "2022-04-11T17:18:10.827412Z",
     "shell.execute_reply": "2022-04-11T17:18:10.826907Z",
     "shell.execute_reply.started": "2022-04-11T17:16:31.322307Z"
    },
    "hidden": true,
    "papermill": {
     "duration": 0.048765,
     "end_time": "2022-04-11T17:18:10.827510",
     "exception": false,
     "start_time": "2022-04-11T17:18:10.778745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 字符索引数\n",
    "max_id = len(tokenizer.word_index)\n",
    "max_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef5b5385",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T17:18:10.912735Z",
     "iopub.status.busy": "2022-04-11T17:18:10.912064Z",
     "iopub.status.idle": "2022-04-11T17:18:10.914722Z",
     "shell.execute_reply": "2022-04-11T17:18:10.915146Z",
     "shell.execute_reply.started": "2022-04-11T17:16:31.331264Z"
    },
    "hidden": true,
    "papermill": {
     "duration": 0.047252,
     "end_time": "2022-04-11T17:18:10.915260",
     "exception": false,
     "start_time": "2022-04-11T17:18:10.868008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115394"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 总字符数\n",
    "dataset_size = tokenizer.document_count\n",
    "dataset_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b075ba8b",
   "metadata": {
    "hidden": true,
    "papermill": {
     "duration": 0.041051,
     "end_time": "2022-04-11T17:18:10.996865",
     "exception": false,
     "start_time": "2022-04-11T17:18:10.955814",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- 现在对完整文本做编码，将每个字符都用ID来表示（减1**使ID从0到38**，而不是1到39）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7623c973",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T17:18:11.086789Z",
     "iopub.status.busy": "2022-04-11T17:18:11.086080Z",
     "iopub.status.idle": "2022-04-11T17:18:11.451240Z",
     "shell.execute_reply": "2022-04-11T17:18:11.450081Z",
     "shell.execute_reply.started": "2022-04-11T17:16:31.339425Z"
    },
    "hidden": true,
    "papermill": {
     "duration": 0.41368,
     "end_time": "2022-04-11T17:18:11.451586",
     "exception": false,
     "start_time": "2022-04-11T17:18:11.037906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19,  5,  8, ..., 20, 26, 10])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[encoded] = np.array(tokenizer.texts_to_sequences([shakespeare_text])) -1\n",
    "encoded  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62200b63",
   "metadata": {
    "heading_collapsed": true,
    "papermill": {
     "duration": 0.040954,
     "end_time": "2022-04-11T17:18:11.537856",
     "exception": false,
     "start_time": "2022-04-11T17:18:11.496902",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 如何区分序列数据集 How to Split a Sequential Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3f7635",
   "metadata": {
    "hidden": true,
    "papermill": {
     "duration": 0.041438,
     "end_time": "2022-04-11T17:18:11.620949",
     "exception": false,
     "start_time": "2022-04-11T17:18:11.579511",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "避免训练集、验证集、测试集发生重合非常重要。\n",
    "\n",
    "当处理时间序列时，\n",
    "- 通常按照时间切分,\n",
    "- 也可以按照其它维度来切分，可以得到更长的时间周期进行训练。如果训练集中的数据存在高度关联性, 则测试集的意义就不大，泛化误差会存在偏移。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5f9f3d",
   "metadata": {
    "hidden": true,
    "papermill": {
     "duration": 0.041051,
     "end_time": "2022-04-11T17:18:11.703553",
     "exception": false,
     "start_time": "2022-04-11T17:18:11.662502",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "在莎士比亚案例中, 可以取90%的文本作为训练集，5%作为验证集，5%作为测试集。在这三个数据之间留出空隙，以避免段落重叠也是非常好的主意。\n",
    "\n",
    "创建`tf.data.Dataset`, 可以从数据集中一个个返回字符."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5151d26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T17:18:13.916986Z",
     "iopub.status.busy": "2022-04-11T17:18:11.789817Z",
     "iopub.status.idle": "2022-04-11T17:18:14.295567Z",
     "shell.execute_reply": "2022-04-11T17:18:14.295134Z",
     "shell.execute_reply.started": "2022-04-11T17:16:31.726484Z"
    },
    "hidden": true,
    "papermill": {
     "duration": 2.550903,
     "end_time": "2022-04-11T17:18:14.295700",
     "exception": false,
     "start_time": "2022-04-11T17:18:11.744797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-11 17:18:11.857193: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-11 17:18:11.945198: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-11 17:18:11.946000: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-11 17:18:11.948423: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-11 17:18:11.949195: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-11 17:18:11.950145: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-11 17:18:11.951026: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-11 17:18:13.900132: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-11 17:18:13.901419: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-11 17:18:13.902509: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-11 17:18:13.903432: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    }
   ],
   "source": [
    "train_size = dataset_size * 90 // 100     # train_size=1003854\n",
    "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e700ebcf",
   "metadata": {
    "papermill": {
     "duration": 0.04208,
     "end_time": "2022-04-11T17:18:14.379593",
     "exception": false,
     "start_time": "2022-04-11T17:18:14.337513",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 将序列数据集切分成多个窗口 Chopping the Sequential Dataset into Multiple Windows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc74a3b2",
   "metadata": {
    "heading_collapsed": true,
    "papermill": {
     "duration": 0.04154,
     "end_time": "2022-04-11T17:18:14.463119",
     "exception": false,
     "start_time": "2022-04-11T17:18:14.421579",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 示例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556e764c",
   "metadata": {
    "hidden": true,
    "papermill": {
     "duration": 0.04142,
     "end_time": "2022-04-11T17:18:14.546415",
     "exception": false,
     "start_time": "2022-04-11T17:18:14.504995",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1. 让我们将序列 0 到 14 拆分为长度为 5 的窗口，每个窗口移动 2\n",
    "\n",
    "        [0, 1, 2, 3, 4], [2, 3, 4, 5, 6], [4, 5, 6, 7, 8], ....\n",
    "    \n",
    "2. 然后将它们打乱，并将它们拆分为`inputs`（前 4 步）和`targets`（后 4 步）\n",
    "\n",
    "        [2, 3, 4, 5, 6] 将被拆分为 [[2, 3, 4, 5], [3, 4, 5, 6]])\n",
    "  \n",
    "3. 然后创建 3 个这样的`inputs`/`targets`对的批次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42d9d2b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T17:18:14.636168Z",
     "iopub.status.busy": "2022-04-11T17:18:14.635428Z",
     "iopub.status.idle": "2022-04-11T17:18:14.641432Z",
     "shell.execute_reply": "2022-04-11T17:18:14.641820Z",
     "shell.execute_reply.started": "2022-04-11T17:16:33.892159Z"
    },
    "hidden": true,
    "papermill": {
     "duration": 0.053443,
     "end_time": "2022-04-11T17:18:14.641993",
     "exception": false,
     "start_time": "2022-04-11T17:18:14.588550",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "initialization(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccf4a80",
   "metadata": {
    "hidden": true,
    "papermill": {
     "duration": 0.041914,
     "end_time": "2022-04-11T17:18:14.726301",
     "exception": false,
     "start_time": "2022-04-11T17:18:14.684387",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- 调节`n_steps`：用短输入序列训练`RNN`更为简单，但是因此`RNN`学不到任何长度超过`n_steps`的规律，所以`n_steps`不要太短。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "206a6066",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T17:18:14.814912Z",
     "iopub.status.busy": "2022-04-11T17:18:14.814069Z",
     "iopub.status.idle": "2022-04-11T17:18:14.818499Z",
     "shell.execute_reply": "2022-04-11T17:18:14.818038Z",
     "shell.execute_reply.started": "2022-04-11T17:16:33.903525Z"
    },
    "hidden": true,
    "papermill": {
     "duration": 0.050324,
     "end_time": "2022-04-11T17:18:14.818623",
     "exception": false,
     "start_time": "2022-04-11T17:18:14.768299",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_steps = 5\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(tf.range(16))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc64528",
   "metadata": {
    "hidden": true,
    "papermill": {
     "duration": 0.062414,
     "end_time": "2022-04-11T17:18:14.923356",
     "exception": false,
     "start_time": "2022-04-11T17:18:14.860942",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- 使用数据集的`window()`，将这个**长序列转化为许多小窗口文本**。每个实例都是完整文本的相对短的子字符串，`RNN`只在这些子字符串上展开。这被称为`截断沿时间反向传播truncated backpropagation through time`\n",
    "    >\n",
    "    > ```python\n",
    "    window(\n",
    "        size, \n",
    "        shift=None, \n",
    "        stride=1, \n",
    "        drop_remainder=False,   \n",
    "        name=None\n",
    "    )\n",
    "    > ```\n",
    "    > - `drop_remainder`:如果最后一个窗口的大小小于 `size`，是否应该删除最后一个窗口。\n",
    "    > - `shift`: 表示**窗口**在每次迭代中**移动**的输入元素的数量.\n",
    "    > - `stride`: 步幅,默认为1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb7c72ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T17:18:15.025275Z",
     "iopub.status.busy": "2022-04-11T17:18:15.024722Z",
     "iopub.status.idle": "2022-04-11T17:18:15.082273Z",
     "shell.execute_reply": "2022-04-11T17:18:15.082852Z",
     "shell.execute_reply.started": "2022-04-11T17:16:33.911299Z"
    },
    "hidden": true,
    "papermill": {
     "duration": 0.106581,
     "end_time": "2022-04-11T17:18:15.083044",
     "exception": false,
     "start_time": "2022-04-11T17:18:14.976463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4]\n",
      "[2, 3, 4, 5, 6]\n",
      "[4, 5, 6, 7, 8]\n",
      "[6, 7, 8, 9, 10]\n",
      "[8, 9, 10, 11, 12]\n",
      "[10, 11, 12, 13, 14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-11 17:18:15.060597: W tensorflow/core/framework/dataset.cc:679] Input of Window will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    }
   ],
   "source": [
    "test_dataset = test_dataset.window(size=n_steps, \n",
    "                                   shift=2, \n",
    "                                   drop_remainder=True)\n",
    "\n",
    "for ds in test_dataset:\n",
    "    print( [elem.numpy() for elem in ds])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e04844",
   "metadata": {
    "hidden": true,
    "papermill": {
     "duration": 0.041999,
     "end_time": "2022-04-11T17:18:15.168547",
     "exception": false,
     "start_time": "2022-04-11T17:18:15.126548",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "    迭代次数: ( len(text)-window_size )//shift +1 = (16-5)//2+1 = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49ef99d",
   "metadata": {
    "hidden": true,
    "papermill": {
     "duration": 0.041625,
     "end_time": "2022-04-11T17:18:15.252431",
     "exception": false,
     "start_time": "2022-04-11T17:18:15.210806",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- 使用`window()`,返回一个嵌套的数据,类似于`list of lists`. 当调用数据集方法处理（比如`shuffle`或做`batch`）每个窗口时，这样会很方便。\n",
    "\n",
    "    但是，不能直接使用嵌套数据集来训练，因为模型要的输入是`tensors`，不是`datasets`。因此，必须调用`flat_map()`方法：\n",
    "    > - `flat_map()`:它能将嵌套数据集转换成**展平**的数据集。\n",
    "    > \n",
    "    >   例: 假设 `{1, 2, 3}` 表示包含张量1、2、3的序列。如果将嵌套数据集 `{{1, 2}, {3, 4, 5, 6}}` 打平，就会得到` {1, 2, 3, 4, 5, 6}` 。\n",
    "    >\n",
    "    >\n",
    "    > - `flat_map()`方法可以接收函数作为参数，可以处理嵌套数据集的每个数据集。\n",
    "    >\n",
    "    >   例: 如果将函数 `lambda ds: ds.batch(2)` 传递给 `flat_map()` ，它能将 `{{1, 2}, {3, 4, 5, 6}}` 转变为` {[1, 2], [3, 4], [5, 6]}` ：这是一个张量大小为2的数据集。\n",
    "    >\n",
    "    >   每个窗口上调用了`batch(window_length)`：因为所有窗口都是这个长度，对于每个窗口，都能得到一个独立的张量。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8a23ef8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T17:18:15.344002Z",
     "iopub.status.busy": "2022-04-11T17:18:15.343455Z",
     "iopub.status.idle": "2022-04-11T17:18:15.436747Z",
     "shell.execute_reply": "2022-04-11T17:18:15.436149Z",
     "shell.execute_reply.started": "2022-04-11T17:16:33.966329Z"
    },
    "hidden": true,
    "papermill": {
     "duration": 0.142516,
     "end_time": "2022-04-11T17:18:15.436895",
     "exception": false,
     "start_time": "2022-04-11T17:18:15.294379",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4]\n",
      "[2, 3, 4, 5, 6]\n",
      "[4, 5, 6, 7, 8]\n",
      "[6, 7, 8, 9, 10]\n",
      "[8, 9, 10, 11, 12]\n",
      "[10, 11, 12, 13, 14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-11 17:18:15.383250: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    }
   ],
   "source": [
    "test_dataset = test_dataset.flat_map(lambda windows:windows.batch(5))\n",
    "\n",
    "for ds in test_dataset:\n",
    "    print( [elem.numpy() for elem in ds])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c382f9",
   "metadata": {
    "hidden": true,
    "papermill": {
     "duration": 0.042586,
     "end_time": "2022-04-11T17:18:15.522208",
     "exception": false,
     "start_time": "2022-04-11T17:18:15.479622",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- 现在的数据集包含连续的窗口，每个有5个字符。因为梯度下降在训练集中的实例`独立同分布`时的效果最好，需要`shuffle`这些窗口。然后我们可以对窗口做`batch`，分割`inputs`（前4个字符）和`targets`(除去第一个字符)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af8e650b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T17:18:15.613704Z",
     "iopub.status.busy": "2022-04-11T17:18:15.613060Z",
     "iopub.status.idle": "2022-04-11T17:18:15.653073Z",
     "shell.execute_reply": "2022-04-11T17:18:15.652558Z",
     "shell.execute_reply.started": "2022-04-11T17:16:34.098471Z"
    },
    "hidden": true,
    "papermill": {
     "duration": 0.088301,
     "end_time": "2022-04-11T17:18:15.653196",
     "exception": false,
     "start_time": "2022-04-11T17:18:15.564895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset = test_dataset.shuffle(10).map(lambda windows:(windows[:-1], windows[1:]))\n",
    "test_dataset = test_dataset.batch(3).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7ee0147",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T17:18:15.744582Z",
     "iopub.status.busy": "2022-04-11T17:18:15.743794Z",
     "iopub.status.idle": "2022-04-11T17:18:15.777986Z",
     "shell.execute_reply": "2022-04-11T17:18:15.778444Z",
     "shell.execute_reply.started": "2022-04-11T17:16:34.156772Z"
    },
    "hidden": true,
    "papermill": {
     "duration": 0.081648,
     "end_time": "2022-04-11T17:18:15.778591",
     "exception": false,
     "start_time": "2022-04-11T17:18:15.696943",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________ Batch 0 \n",
      "X_batch\n",
      "[[6 7 8 9]\n",
      " [2 3 4 5]\n",
      " [4 5 6 7]]\n",
      "===== \n",
      "Y_batch\n",
      "[[ 7  8  9 10]\n",
      " [ 3  4  5  6]\n",
      " [ 5  6  7  8]]\n",
      "____________________ Batch 1 \n",
      "X_batch\n",
      "[[ 0  1  2  3]\n",
      " [ 8  9 10 11]\n",
      " [10 11 12 13]]\n",
      "===== \n",
      "Y_batch\n",
      "[[ 1  2  3  4]\n",
      " [ 9 10 11 12]\n",
      " [11 12 13 14]]\n"
     ]
    }
   ],
   "source": [
    "for index, (X_batch, Y_batch) in enumerate(test_dataset):\n",
    "    print( \"_\"*20, \"Batch\", index, \n",
    "           \"\\nX_batch\")\n",
    "    print( X_batch.numpy() )\n",
    "    print( \"=\"*5, \n",
    "           \"\\nY_batch\" )\n",
    "    print( Y_batch.numpy() )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d91e324",
   "metadata": {
    "papermill": {
     "duration": 0.042825,
     "end_time": "2022-04-11T17:18:15.864566",
     "exception": false,
     "start_time": "2022-04-11T17:18:15.821741",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 使用在莎士比亚数据集上"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157ddea2",
   "metadata": {
    "papermill": {
     "duration": 0.043526,
     "end_time": "2022-04-11T17:18:15.951772",
     "exception": false,
     "start_time": "2022-04-11T17:18:15.908246",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<img src=\"./images/other/15-22.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53fa9393",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T17:18:16.047084Z",
     "iopub.status.busy": "2022-04-11T17:18:16.045141Z",
     "iopub.status.idle": "2022-04-11T17:18:16.049960Z",
     "shell.execute_reply": "2022-04-11T17:18:16.049482Z",
     "shell.execute_reply.started": "2022-04-11T17:16:34.208754Z"
    },
    "papermill": {
     "duration": 0.053697,
     "end_time": "2022-04-11T17:18:16.050083",
     "exception": false,
     "start_time": "2022-04-11T17:18:15.996386",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "initialization(42)\n",
    "\n",
    "n_steps = 100 \n",
    "window_length = n_steps + 1   # target = input 后移 1 个字符\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49da8dd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T17:18:16.142934Z",
     "iopub.status.busy": "2022-04-11T17:18:16.142393Z",
     "iopub.status.idle": "2022-04-11T17:18:16.165685Z",
     "shell.execute_reply": "2022-04-11T17:18:16.165144Z",
     "shell.execute_reply.started": "2022-04-11T17:16:34.224919Z"
    },
    "papermill": {
     "duration": 0.072113,
     "end_time": "2022-04-11T17:18:16.165809",
     "exception": false,
     "start_time": "2022-04-11T17:18:16.093696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = dataset.window(size=window_length, shift=1, drop_remainder=True)\n",
    "dataset = dataset.flat_map(lambda window: window.batch(window_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "419c4e45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T17:18:16.258428Z",
     "iopub.status.busy": "2022-04-11T17:18:16.257634Z",
     "iopub.status.idle": "2022-04-11T17:18:16.284682Z",
     "shell.execute_reply": "2022-04-11T17:18:16.284176Z",
     "shell.execute_reply.started": "2022-04-11T17:16:34.270313Z"
    },
    "papermill": {
     "duration": 0.075423,
     "end_time": "2022-04-11T17:18:16.284789",
     "exception": false,
     "start_time": "2022-04-11T17:18:16.209366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle(10000).batch(batch_size)\n",
    "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5bab93",
   "metadata": {
    "papermill": {
     "duration": 0.042742,
     "end_time": "2022-04-11T17:18:16.370701",
     "exception": false,
     "start_time": "2022-04-11T17:18:16.327959",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- 特征编码可以选择`独热编码`或`嵌入`。这里使用**独热编码**，因为独立字符不多."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21d2015c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T17:18:16.462829Z",
     "iopub.status.busy": "2022-04-11T17:18:16.462005Z",
     "iopub.status.idle": "2022-04-11T17:18:16.486208Z",
     "shell.execute_reply": "2022-04-11T17:18:16.485651Z",
     "shell.execute_reply.started": "2022-04-11T17:16:34.320869Z"
    },
    "papermill": {
     "duration": 0.072948,
     "end_time": "2022-04-11T17:18:16.486328",
     "exception": false,
     "start_time": "2022-04-11T17:18:16.413380",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = dataset.map(lambda X_batch, Y_batch:\n",
    "                      (tf.one_hot(X_batch, depth=max_id), Y_batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c3d132",
   "metadata": {
    "papermill": {
     "duration": 0.042611,
     "end_time": "2022-04-11T17:18:16.574623",
     "exception": false,
     "start_time": "2022-04-11T17:18:16.532012",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- `prefetch()`实现预提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c54c5c89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T17:18:16.665116Z",
     "iopub.status.busy": "2022-04-11T17:18:16.664484Z",
     "iopub.status.idle": "2022-04-11T17:18:16.666983Z",
     "shell.execute_reply": "2022-04-11T17:18:16.667411Z",
     "shell.execute_reply.started": "2022-04-11T17:16:34.370388Z"
    },
    "papermill": {
     "duration": 0.049609,
     "end_time": "2022-04-11T17:18:16.667533",
     "exception": false,
     "start_time": "2022-04-11T17:18:16.617924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c27054d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T17:18:16.757414Z",
     "iopub.status.busy": "2022-04-11T17:18:16.756649Z",
     "iopub.status.idle": "2022-04-11T17:18:18.617491Z",
     "shell.execute_reply": "2022-04-11T17:18:18.618103Z",
     "shell.execute_reply.started": "2022-04-11T17:16:34.398527Z"
    },
    "papermill": {
     "duration": 1.908102,
     "end_time": "2022-04-11T17:18:18.618298",
     "exception": false,
     "start_time": "2022-04-11T17:18:16.710196",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 100, 39) (32, 100)\n"
     ]
    }
   ],
   "source": [
    "for X_batch, Y_batch in dataset.take(1):\n",
    "    print(X_batch.shape, Y_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc6e458",
   "metadata": {
    "papermill": {
     "duration": 0.043275,
     "end_time": "2022-04-11T17:18:18.706560",
     "exception": false,
     "start_time": "2022-04-11T17:18:18.663285",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 搭建并训练Char-RNN模型 Building and Training the Char-RNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3b8ca6",
   "metadata": {
    "papermill": {
     "duration": 0.043715,
     "end_time": "2022-04-11T17:18:18.793391",
     "exception": false,
     "start_time": "2022-04-11T17:18:18.749676",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "根据前面的100个字符预测下一个字符:\n",
    "\n",
    "- 使用一个`RNN`，含有两个`GRU`层，每个128个单元，每个单元对`输入dropout`和`隐藏态recurrent_dropout`的丢失率是20%。如果需要的话，后面可以微调这些超参数。\n",
    "\n",
    "- 输出层是一个时间分布的紧密层，有39个单元,即`max_id`，因为文本中有39个不同的字符，需要输出每个可能字符（在每个时间步）的概率。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3604d6",
   "metadata": {
    "papermill": {
     "duration": 0.043302,
     "end_time": "2022-04-11T17:18:18.880650",
     "exception": false,
     "start_time": "2022-04-11T17:18:18.837348",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "> 注意：当使用以下参数的默认值时，`GRU` 类将只使用 `GPU`（如果有的话）：`activation`、`recurrent_activation`、`recurrent_dropout`、`unroll`、`use_bias` 和 `reset_after`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d0f54bea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T17:18:18.973978Z",
     "iopub.status.busy": "2022-04-11T17:18:18.973235Z",
     "iopub.status.idle": "2022-04-11T17:18:19.377184Z",
     "shell.execute_reply": "2022-04-11T17:18:19.376695Z",
     "shell.execute_reply.started": "2022-04-11T17:16:36.472563Z"
    },
    "papermill": {
     "duration": 0.452901,
     "end_time": "2022-04-11T17:18:19.377315",
     "exception": false,
     "start_time": "2022-04-11T17:18:18.924414",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(128,\n",
    "                     return_sequences=True,\n",
    "                     input_shape=[None, max_id],\n",
    "                     # dropout=0.2, recurrent_dropout=0.2\n",
    "                     dropout=0.2),\n",
    "    keras.layers.GRU(128, return_sequences=True, dropout=0.2),\n",
    "    keras.layers.TimeDistributed(\n",
    "        keras.layers.Dense(max_id, activation=\"softmax\"))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "54da25e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T17:18:19.475684Z",
     "iopub.status.busy": "2022-04-11T17:18:19.474835Z",
     "iopub.status.idle": "2022-04-11T19:43:52.847227Z",
     "shell.execute_reply": "2022-04-11T19:43:52.846627Z"
    },
    "papermill": {
     "duration": 8733.426147,
     "end_time": "2022-04-11T19:43:52.847389",
     "exception": false,
     "start_time": "2022-04-11T17:18:19.421242",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-11 17:18:24.544045: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31368/31368 [==============================] - 408s 13ms/step - loss: 1.6206\n",
      "Epoch 2/20\n",
      "31368/31368 [==============================] - 401s 13ms/step - loss: 1.5369\n",
      "Epoch 3/20\n",
      "31368/31368 [==============================] - 402s 13ms/step - loss: 1.5170\n",
      "Epoch 4/20\n",
      "31368/31368 [==============================] - 421s 13ms/step - loss: 1.5057\n",
      "Epoch 5/20\n",
      "31368/31368 [==============================] - 400s 13ms/step - loss: 1.4983\n",
      "Epoch 6/20\n",
      "31368/31368 [==============================] - 408s 13ms/step - loss: 1.4929\n",
      "Epoch 7/20\n",
      "31368/31368 [==============================] - 401s 13ms/step - loss: 1.4893\n",
      "Epoch 8/20\n",
      "31368/31368 [==============================] - 417s 13ms/step - loss: 1.4866\n",
      "Epoch 9/20\n",
      "31368/31368 [==============================] - 401s 13ms/step - loss: 1.4845\n",
      "Epoch 10/20\n",
      "31368/31368 [==============================] - 408s 13ms/step - loss: 1.4822\n",
      "Epoch 11/20\n",
      "31368/31368 [==============================] - 409s 13ms/step - loss: 1.4808\n",
      "Epoch 12/20\n",
      "31368/31368 [==============================] - 414s 13ms/step - loss: 1.4795\n",
      "Epoch 13/20\n",
      "31368/31368 [==============================] - 410s 13ms/step - loss: 1.4788\n",
      "Epoch 14/20\n",
      "31368/31368 [==============================] - 409s 13ms/step - loss: 1.4774\n",
      "Epoch 15/20\n",
      "31368/31368 [==============================] - 423s 13ms/step - loss: 1.4764\n",
      "Epoch 16/20\n",
      "31368/31368 [==============================] - 428s 14ms/step - loss: 1.4756\n",
      "Epoch 17/20\n",
      "31368/31368 [==============================] - 411s 13ms/step - loss: 1.4753\n",
      "Epoch 18/20\n",
      "31368/31368 [==============================] - 401s 13ms/step - loss: 1.4738\n",
      "Epoch 19/20\n",
      "31368/31368 [==============================] - 429s 14ms/step - loss: 1.4733\n",
      "Epoch 20/20\n",
      "31368/31368 [==============================] - 402s 13ms/step - loss: 1.4725\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
    "history = model.fit(dataset, epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "29524a6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T19:45:24.611422Z",
     "iopub.status.busy": "2022-04-11T19:45:24.610764Z",
     "iopub.status.idle": "2022-04-11T19:45:24.648547Z",
     "shell.execute_reply": "2022-04-11T19:45:24.648062Z"
    },
    "papermill": {
     "duration": 46.125412,
     "end_time": "2022-04-11T19:45:24.648668",
     "exception": false,
     "start_time": "2022-04-11T19:44:38.523256",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save(\"./models/my_CharRNN_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "76baa6ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T19:46:56.411233Z",
     "iopub.status.busy": "2022-04-11T19:46:56.410554Z",
     "iopub.status.idle": "2022-04-11T19:46:56.680212Z",
     "shell.execute_reply": "2022-04-11T19:46:56.679604Z"
    },
    "papermill": {
     "duration": 45.859348,
     "end_time": "2022-04-11T19:46:56.680446",
     "exception": true,
     "start_time": "2022-04-11T19:46:10.821098",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_27/593024705.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mhistory_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'accuracy'"
     ]
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "train_loss = history_dict[\"loss\"]\n",
    "train_accuracy = history_dict[\"accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e470a9d3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "# figure 1\n",
    "plt.figure()\n",
    "plt.plot(range(epochs), train_loss, label='train_loss')\n",
    "plt.legend()\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "# figure 2\n",
    "plt.figure()\n",
    "plt.legend()\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c41dee9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8994.080817,
   "end_time": "2022-04-11T19:47:47.130309",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-04-11T17:17:53.049492",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
