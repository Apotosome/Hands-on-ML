{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48eb242c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-16T16:06:58.887578Z",
     "iopub.status.busy": "2022-05-16T16:06:58.886980Z",
     "iopub.status.idle": "2022-05-16T16:07:21.195944Z",
     "shell.execute_reply": "2022-05-16T16:07:21.194582Z"
    },
    "papermill": {
     "duration": 22.323092,
     "end_time": "2022-05-16T16:07:21.198570",
     "exception": false,
     "start_time": "2022-05-16T16:06:58.875478",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "tensorflow-io 0.21.0 requires tensorflow-io-gcs-filesystem==0.21.0, which is not installed.\r\n",
      "tensorflow 2.6.3 requires absl-py~=0.10, but you have absl-py 1.0.0 which is incompatible.\r\n",
      "tensorflow 2.6.3 requires numpy~=1.19.2, but you have numpy 1.21.6 which is incompatible.\r\n",
      "tensorflow 2.6.3 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\r\n",
      "tensorflow 2.6.3 requires wrapt~=1.12.1, but you have wrapt 1.14.0 which is incompatible.\r\n",
      "tensorflow-transform 1.7.0 requires pyarrow<6,>=1, but you have pyarrow 7.0.0 which is incompatible.\r\n",
      "tensorflow-transform 1.7.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<2.9,>=1.15.5, but you have tensorflow 2.6.3 which is incompatible.\r\n",
      "tensorflow-serving-api 2.8.0 requires tensorflow<3,>=2.8.0, but you have tensorflow 2.6.3 which is incompatible.\r\n",
      "rich 12.4.1 requires typing-extensions<5.0,>=4.0.0; python_version < \"3.9\", but you have typing-extensions 3.10.0.2 which is incompatible.\r\n",
      "pytorch-lightning 1.6.3 requires typing-extensions>=4.0.0, but you have typing-extensions 3.10.0.2 which is incompatible.\r\n",
      "pytools 2022.1.7 requires typing-extensions>=4.0; python_version < \"3.11\", but you have typing-extensions 3.10.0.2 which is incompatible.\r\n",
      "flax 0.4.2 requires typing-extensions>=4.1.1, but you have typing-extensions 3.10.0.2 which is incompatible.\r\n",
      "flake8 4.0.1 requires importlib-metadata<4.3; python_version < \"3.8\", but you have importlib-metadata 4.11.3 which is incompatible.\r\n",
      "apache-beam 2.37.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.4 which is incompatible.\r\n",
      "apache-beam 2.37.0 requires httplib2<0.20.0,>=0.8, but you have httplib2 0.20.4 which is incompatible.\r\n",
      "apache-beam 2.37.0 requires pyarrow<7.0.0,>=0.15.1, but you have pyarrow 7.0.0 which is incompatible.\r\n",
      "aioitertools 0.10.0 requires typing_extensions>=4.0; python_version < \"3.10\", but you have typing-extensions 3.10.0.2 which is incompatible.\r\n",
      "aiobotocore 2.2.0 requires botocore<1.24.22,>=1.24.21, but you have botocore 1.25.12 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q torchdata==0.3.0 torchtext==0.12 spacy==3.2 torch==1.11.0 GPUtil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "065b474f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-16T16:07:21.221328Z",
     "iopub.status.busy": "2022-05-16T16:07:21.221108Z",
     "iopub.status.idle": "2022-05-16T16:07:22.859896Z",
     "shell.execute_reply": "2022-05-16T16:07:22.859165Z"
    },
    "papermill": {
     "duration": 1.652506,
     "end_time": "2022-05-16T16:07:22.861919",
     "exception": false,
     "start_time": "2022-05-16T16:07:21.209413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1 导入必备的库\n",
    "import copy\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 3 Model Architecture\n",
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder, src_embed, tgt_embed, generator):\n",
    "        \"\"\"\n",
    "        初始化函数\n",
    "        :param encoder: 编码器对象\n",
    "        :param decoder: 解码器对象\n",
    "        :param src_embed: 源数据嵌入函数\n",
    "        :param tgt_embed: 目标数据嵌入函数\n",
    "        :param generator: 类别生成器对象\n",
    "        \"\"\"\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_embed = src_embed\n",
    "        self.tgt_embed = tgt_embed\n",
    "        self.generator = generator\n",
    "\n",
    "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
    "        \"\"\"\n",
    "        将src, src_mask传入编码函数，得到结果后与src_mask, tgt和tgt_mask一同传给解码函数\n",
    "        :param src: 源数据\n",
    "        :param tgt: 目标数据\n",
    "        :param src_mask: 源数据掩码张量\n",
    "        :param tgt_mask: 目标数据掩码张量\n",
    "        \"\"\"\n",
    "        memory = self.encode(src, src_mask)\n",
    "        res = self.decode(memory, src_mask, tgt, tgt_mask)\n",
    "        return res\n",
    "\n",
    "    def encode(self, src, src_mask):\n",
    "        \"\"\"\n",
    "        编码函数，使用src_embed对source做处理，然后和src_mask一起传给self.encoder\n",
    "        \"\"\"\n",
    "        source_embeddings = self.src_embed(src)\n",
    "        return self.encoder(source_embeddings, src_mask)\n",
    "\n",
    "    def decode(self, memory, src_mask, tgt, tgt_mask):\n",
    "        \"\"\"\n",
    "        解码函数，使用tgt_embed对target做处理，然后和src_mask,tgt_mask,memory一起传给self.decoder\n",
    "        \"\"\"\n",
    "        target_embeddings = self.tgt_embed(tgt)\n",
    "        return self.decoder(target_embeddings, memory, src_mask, tgt_mask)\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \"\"\"\n",
    "    将线性层和softmax计算层一起实现， 把类的名字叫做Generator，生成器类\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model, vocab):\n",
    "        \"\"\"\n",
    "        初始化函数\n",
    "        :param d_model: 嵌入的维度\n",
    "        :param vocab: vocab.size -> 词表的大小\n",
    "        \"\"\"\n",
    "        super(Generator, self).__init__()\n",
    "        self.proj = nn.Linear(in_features=d_model, out_features=vocab)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        输入是上一层的输出张量x\n",
    "        使用上一步得到的self.proj对x进行线性变化, 然后使用F中已经实现的log_softmax进行softmax处理。\n",
    "        \"\"\"\n",
    "        softmax = F.log_softmax(self.proj(x), dim=-1)\n",
    "        return softmax\n",
    "\n",
    "\n",
    "# 3.1 Encoder and Decoder Stacks\n",
    "\n",
    "# 3.1.1 Encoder\n",
    "def clone(module, N):\n",
    "    \"\"\"\n",
    "    用于克隆多份结构\n",
    "    \"\"\"\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, layer, N):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layers = clone(layer, N)  # 实现简单的克隆，在叠加在一起\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \"\"\"\n",
    "        将输入（和掩码）依次通过每一层。\n",
    "        \"\"\"\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return self.norm(x)\n",
    "\n",
    "\n",
    "# 3.1.2 Layer Normalization and Residual Connections\n",
    "class LayerNorm(nn.Module):\n",
    "\n",
    "    def __init__(self, feature_size, eps=1e-6):\n",
    "        \"\"\"\n",
    "        初始化函数\n",
    "        :param feature_size: 词嵌入的维度\n",
    "        :param eps: 防止分母为0，默认是1e-6\n",
    "        \"\"\"\n",
    "        super(LayerNorm, self).__init__()\n",
    "        # 使用nn.parameter封装，代表他们是模型的参数\n",
    "        self.gamma = nn.Parameter(torch.ones(feature_size))  # 缩放参数向量 初始化为1张量\n",
    "        self.beta = nn.Parameter(torch.zeros(feature_size))  # 平移参数向量 初始化为0张量\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        1. 对输入变量x求其最后一个维度,即词嵌入维度的均值，并保持输出维度与输入维度一致\n",
    "        2. 求最后一个维度的标准差，进行规范化：用x减去均值除以标准差\n",
    "        3. 对结果乘以我们的缩放参数gamma, *表示点乘，加上位移参beta\n",
    "        :param x: 来自上一层的输出\n",
    "        \"\"\"\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return (x - mean) / (std + self.eps) * self.gamma + self.beta\n",
    "\n",
    "\n",
    "class SublayerConnection(nn.Module):\n",
    "    \"\"\"\n",
    "    SublayerConnection类:实现子层连接结构.𝑥表示上一层添加了残差连接的输出，这一层添加了残差连接的输出需要将  𝑥  执行层级归一化，\n",
    "    然后馈送到 Multi-Head Attention 层或全连接层，添加 Dropout 操作后可作为这一子层级的输出。最后将该子层的输出向量与输入向量相加得到下一层的输入。\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, size, dropout):\n",
    "        \"\"\"\n",
    "        :param size: 𝑑𝑚𝑜𝑑𝑒𝑙=512\n",
    "        :param dropout: 丢弃参数\n",
    "        \"\"\"\n",
    "        super(SublayerConnection, self).__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        # 原方案：先将x执行层级归一化\n",
    "        # sublayer_out = sublayer(self.norm(x))\n",
    "        # return x + self.dropout(sublayer_out)\n",
    "        # 改进版本：取出norm 加快收敛速度\n",
    "        sublayer_out = sublayer(x)\n",
    "        sublayer_out = self.dropout(sublayer_out)\n",
    "        return x + self.norm(sublayer_out)\n",
    "\n",
    "\n",
    "# 3.1.3 Encoder Layer\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, size, self_attention, feed_forward, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = self_attention\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clone(module=SublayerConnection(size, dropout), N=2)  # 两次的跳过连接\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \"\"\"\n",
    "        第一个子层包括一个多头自注意力层和规范化层以及一个残差连接\n",
    "        第二个子层包括一个前馈全连接层和规范化层以及一个残差连接\n",
    "        \"\"\"\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))  # 输入 Query、Key 和 Value 都为 x 就表示自注意力。\n",
    "        z = self.sublayer[1](x, self.feed_forward)\n",
    "        return z\n",
    "\n",
    "\n",
    "# 3.1.4 Decoder\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, layer, N):\n",
    "        \"\"\"\n",
    "        :param layer: 解码器层layer\n",
    "        :param N: 解码器层的个数N\n",
    "        \"\"\"\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = clone(layer, N)  # 实现简单的克隆，在叠加在一起\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "\n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, memory, src_mask, tgt_mask)\n",
    "        return self.norm(x)\n",
    "\n",
    "\n",
    "# 3.1.5 Decoder Layer\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, size, self_attention, src_attn, feed_forward, dropout):\n",
    "        \"\"\"\n",
    "        :param self_attention: 多头自注意力对象，该注意力机制需要Q=K=V\n",
    "        :param src_attn: 多头注意力对象，这里Q!=K=V\n",
    "        :param dropout: dropout置0比率\n",
    "        \"\"\"\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.self_attn = self_attention\n",
    "        self.src_attn = src_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clone(module=SublayerConnection(size, dropout), N=3)  # 三次的跳过连接\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        \"\"\"\n",
    "        :param x: 上一层的输入\n",
    "        :param memory: 来自编码器层的语义存储变量\n",
    "        :param src_mask: 源数据掩码张量\n",
    "        :param tgt_mask: 目标数据掩码张量\n",
    "        \"\"\"\n",
    "\n",
    "        \"\"\"\n",
    "        将x传入第一个子层结构，第一个子层结构的输入分别是x和self-attn函数，因为是自注意力机制，所以Q,K,V都是x，\n",
    "        最后一个参数时目标数据掩码张量，这时要对目标数据进行遮掩，因为此时模型可能还没有生成任何目标数据。\n",
    "        比如在解码器准备生成第一个字符或词汇时，我们其实已经传入了第一个字符以便计算损失，但是我们不希望在生成第一个字符时模型能利用这个信息，\n",
    "        因此我们会将其遮掩，同样生成第二个字符或词汇时，模型只能使用第一个字符或词汇信息，第二个字符以及之后的信息都不允许被模型使用。\n",
    "        \"\"\"\n",
    "        m = memory\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))  # 输入 Query、Key 和 Value 都为 x 就表示自注意力。\n",
    "        \"\"\"\n",
    "        接着进入第二个子层，这个子层中常规的注意力机制，q是输入x;\n",
    "        k,v是编码层输出memory，同样也传入source_mask，但是进行源数据遮掩的原因并非是抑制信息泄露，而是遮蔽掉对结果没有意义的padding。\n",
    "        \"\"\"\n",
    "        x = self.sublayer[1](x, lambda x: self.src_attn(x, m, m, src_mask))\n",
    "        \"\"\"\n",
    "        最后一个子层就是前馈全连接子层，经过它的处理后就可以返回结果，这就是我们的解码器结构\n",
    "        \"\"\"\n",
    "        z = self.sublayer[2](x, self.feed_forward)\n",
    "        return z\n",
    "\n",
    "\n",
    "# 3.1.6 Mask\n",
    "def subsequent_mask(size):\n",
    "    \"\"\"\n",
    "    生成向后遮掩的掩码张量->形成一个三角矩阵\n",
    "    :param size: 掩码张量最后两个维度的大小, 最后两维形成一个方阵\n",
    "    \"\"\"\n",
    "    attn_shape = (1, size, size)\n",
    "\n",
    "    # 然后使用np.ones()向这个形状中添加1元素，np.triu()形成上三角阵\n",
    "    mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
    "\n",
    "    # 最后将numpy类型转化为torch中的tensor，内部做一个1- 的操作。这个其实是做了一个三角阵的反转，subsequent_mask中的每个元素都会被1减。\n",
    "    # 如果是0，subsequent_mask中的该位置由0变成1\n",
    "    # 如果是1，subsequent_mask中的该位置由1变成0\n",
    "    return torch.from_numpy(mask) == 0\n",
    "\n",
    "\n",
    "# 3.2 Attention\n",
    "\n",
    "# 3.2.1 Scaled Dot-Product Attention\n",
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    \"\"\"\n",
    "    实现了缩放点积注意力\n",
    "    1. 首先取query的最后一维的大小，对应词嵌入维度\n",
    "    2. 利用公式计算注意力分数scores, 这里面key是将最后两个维度进行转置 -> (句子长度维度,词(多头)向量维度)\n",
    "    3. 判断是否使用掩码张量\n",
    "    4. 对scores的最后一维进行softmax操作，获得最终的注意力张量\n",
    "    5. 判断是否使用dropout进行随机置0\n",
    "    6. 最后，将p_attn与value张量相乘获得最终的query注意力表示，同时返回注意力张量\n",
    "    \"\"\"\n",
    "    d_k = query.size(-1)\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "\n",
    "    if mask is not None:\n",
    "        # 将掩码张量和scores张量每个位置一一比较\n",
    "        # 如果掩码张量则对应的scores张量相同，则用-1e9来替换\n",
    "        scores = scores.masked_fill(mask == 0, value=-1e9)\n",
    "\n",
    "    p_attn = F.softmax(scores, dim=-1)\n",
    "\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "\n",
    "    attn = torch.matmul(p_attn, value)\n",
    "    return attn, p_attn\n",
    "\n",
    "\n",
    "# 3.2.2 Multi-Head Attention\n",
    "\n",
    "\n",
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, n_heads, d_model, dropout=0.1):\n",
    "        \"\"\"\n",
    "        :param n_heads: 注意力头数\n",
    "        :param d_model: 词嵌入维度\n",
    "        :param dropout: 比率默认为0.1\n",
    "        \"\"\"\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        # 判断n_heads是否能被d_model整除 -> embedding_dim / n_heads\n",
    "        assert d_model % n_heads == 0\n",
    "        self.d_k = d_model // n_heads  # 512//8=64\n",
    "        self.h = n_heads  # 8\n",
    "\n",
    "        # 创建linear层，并且克隆4个 -> Q,K,V各一个，最后拼接的矩阵还需要一个\n",
    "        self.linear = clone(module=nn.Linear(d_model, d_model), N=4)  # 512*512\n",
    "        self.p_attn = None  # 代表最后得到的注意力张量\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        \"\"\"\n",
    "        1. 从 d_model(512) --> h*d_k(8*64) 批量执行所有线性投影\n",
    "        2. 将注意力集中在所有投影向量上\n",
    "        3. Concat并最终应用到线性层\n",
    "        \"\"\"\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(1)  # 拓展维度，表示多头中的第n头\n",
    "        n_batches = query.size(0)  # batch_size代表有多少条样本\n",
    "\n",
    "        \"\"\"\n",
    "        1. 首先利用zip将输入QKV与三个线性层组到一起，然后利用for循环，将输入QKV分别传到线性层中,\n",
    "           使用view()对线性变换的结构进行维度重塑，为每个头分割输入\n",
    "               多加了一个维度h代表头，这样就意味着每个头可以获得一部分词特征组成的句子\n",
    "               其中的-1代表自适应维度，即m句子长度维度，将自动计算这里的值\n",
    "           然后对第二维和第三维进行转置操作：\n",
    "               原因：为了让代表句子长度维度和词向量维度能够相邻，这样注意力机制才能找到词义与句子位置的关系，\n",
    "               从attention函数中可以看到，利用的是原始输入的倒数第一和第二维，这样我们就得到了每个头的输入\n",
    "        \"\"\"\n",
    "        query, key, value = [\n",
    "            lin(x).view(n_batches, -1, self.h, self.d_k).transpose(1, 2)  # -1 <-> self.h\n",
    "            for lin, x in zip(self.linear, (query, key, value))\n",
    "        ]\n",
    "        \"\"\"\n",
    "        2. 得到每个头的输入后，接下来就是将他们传入到attention中，\n",
    "           这里直接调用我们之前实现的attention函数，同时也将mask和dropout传入其中\n",
    "        \"\"\"\n",
    "        attn, self.p_attn = attention(query, key, value, mask, self.dropout)\n",
    "        \"\"\"\n",
    "        3. 通过多头注意力计算后，我们就得到了每个头计算结果组成的4维张量，我们需要将其转换为输入的形状以方便后续的计算，\n",
    "           因此这里开始进行第一步处理环节的逆操作，先对第二和第三维进行转置，\n",
    "           然后使用contiguous(): 能够让转置后的张量应用view()，否则将无法直接使用.\n",
    "           下一步就是使用view重塑形状，变成和输入形状相同。  \n",
    "           最后使用线性层列表中的最后一个线性变换得到最终的多头注意力结构的输出\n",
    "        \"\"\"\n",
    "        concat = attn.transpose(1, 2).contiguous().view(n_batches, -1, self.h * self.d_k)\n",
    "        x = self.linear[-1](concat)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# 3.3 Position-wise Feed-Forward Networks\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        \"\"\"\n",
    "        :param d_model: 通过前馈全连接层后输入和输出的维度不变\n",
    "        :param d_ff: 内部维度：第二个线性层的输入维度和第一个线性层的输出\n",
    "        \"\"\"\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        首先经过第一个线性层，然后使用F中的relu函数进行激活，\n",
    "        之后再使用dropout进行随机置0，最后通过第二个线性层w2，返回最终结果\n",
    "        \"\"\"\n",
    "        x = self.w_2(self.dropout(F.relu(self.w_1(x))))\n",
    "        return x\n",
    "\n",
    "\n",
    "# 3.4 Embeddings and Softmax\n",
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Embeddings, self).__init__()\n",
    "        self.lut = nn.Embedding(vocab, d_model)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: 这里代表输入给模型的单词文本通过词表映射后的one-hot向量\n",
    "        :return: 将x传给self.lut并与根号下self.d_model相乘作为结果返回\n",
    "        \"\"\"\n",
    "        return self.lut(x) * math.sqrt(self.d_model)\n",
    "\n",
    "\n",
    "# 3.5 Positional Encoding\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        \"\"\"\n",
    "        :param d_model: 词嵌入维度 这里是512维\n",
    "        :param dropout: 词嵌入维度\n",
    "        :param max_len: 每个句子的最大长度\n",
    "        \"\"\"\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # 使用与原公式等价的表示\n",
    "        # 目的是避免中间的数值计算结果超出float的范围\n",
    "        pos_embed = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)  # 0->4999 再插入一个维度(5000,1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model)\n",
    "        )  # shape=[256]\n",
    "        # div_term 实现的是分母\n",
    "        # pe[:, 0::2] 表示第二个维度从 0 开始以间隔为 2 取值，即偶数。\n",
    "        pos_embed[:, ::2] = torch.sin(position * div_term)  # shape=[max_len, 256]\n",
    "        pos_embed[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        pos_embed = pos_embed.unsqueeze(0)  # shape=[1, 500, 512]\n",
    "        self.register_buffer('pe', pos_embed)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, : x.size(1)].requires_grad_(False)\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "# 3.6 Full Model\n",
    "def make_model(src_vocab, tgt_vocab, N=6, d_model=512, d_ff=2048, h=8, dropout=0.1):\n",
    "    \"\"\"\n",
    "    构建模型\n",
    "    :param src_vocab: 输入词表大小\n",
    "    :param tgt_vocab: 目标词表大小\n",
    "    :param N: 编码器和解码器堆叠的基础模块个数\n",
    "    :param d_model: 词嵌入的维度\n",
    "    :param d_ff: 逐位置的前馈网络中的内部维度\n",
    "    :param h: 注意力头的个数\n",
    "    :param dropout:\n",
    "    \"\"\"\n",
    "    c = copy.deepcopy\n",
    "    attn = MultiHeadedAttention(n_heads=h, d_model=d_model, dropout=dropout)\n",
    "    ff = PositionwiseFeedForward(d_model=d_model, d_ff=d_ff, dropout=dropout)\n",
    "    position = PositionalEncoding(d_model=d_model, dropout=dropout)\n",
    "    # -------\n",
    "    encoderLayer = EncoderLayer(size=d_model, self_attention=c(attn), feed_forward=c(ff), dropout=dropout)\n",
    "    decoderLayer = DecoderLayer(size=d_model, self_attention=c(attn), src_attn=c(attn), feed_forward=c(ff),\n",
    "                                dropout=dropout)\n",
    "    srcEmbed = Embeddings(d_model=d_model, vocab=src_vocab)\n",
    "    tgtEmbed = Embeddings(d_model=d_model, vocab=tgt_vocab)\n",
    "    generator = Generator(d_model=d_model, vocab=tgt_vocab)\n",
    "    # -------\n",
    "\n",
    "    model = EncoderDecoder(\n",
    "        encoder=Encoder(layer=encoderLayer, N=N),\n",
    "        decoder=Decoder(layer=decoderLayer, N=N),\n",
    "        src_embed=nn.Sequential(srcEmbed, c(position)),\n",
    "        tgt_embed=nn.Sequential(tgtEmbed, c(position)),\n",
    "        generator=generator\n",
    "    )\n",
    "    # 初始化参数: 使用Glorot初始化: 1/𝑓𝑎𝑛_𝑎𝑣𝑔, 𝑓𝑎𝑛_𝑎𝑣𝑔=(𝑓𝑎𝑛_𝑖𝑛 +𝑓𝑎𝑛_𝑜𝑢𝑡)/2\n",
    "    for p in model.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_uniform_(p)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fa95f8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-16T16:07:22.883687Z",
     "iopub.status.busy": "2022-05-16T16:07:22.883167Z",
     "iopub.status.idle": "2022-05-16T16:07:23.076385Z",
     "shell.execute_reply": "2022-05-16T16:07:23.075718Z"
    },
    "papermill": {
     "duration": 0.206293,
     "end_time": "2022-05-16T16:07:23.078469",
     "exception": false,
     "start_time": "2022-05-16T16:07:22.872176",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "\n",
    "import altair as alt\n",
    "\n",
    "\n",
    "# 5 Training\n",
    "# 5.1 Batched and Masking\n",
    "class Batch:\n",
    "    def __init__(self, src, tgt, pad=2):\n",
    "        \"\"\"\n",
    "        :param pad: 默认2 表示<blank>\n",
    "        \"\"\"\n",
    "        self.src = src\n",
    "        # 将与令牌匹配的位置表示为False, 否则为True\n",
    "        # 并在倒数第二个维度后面添加一维度\n",
    "        self.src_mask = (src != pad).unsqueeze(-2)\n",
    "\n",
    "        if tgt is not None:\n",
    "            self.tgt = tgt[:, :-1]  # Decoder的输入，即除去最后一个结束token的部分\n",
    "            self.tgt_y = tgt[:, 1:]  # Decoder的期望输入，即除去首个一个起始token的部分\n",
    "            self.tgt_mask = self.make_std_mask(self.tgt, pad)\n",
    "            self.ntokens = (self.tgt_y != pad).data.sum()  # 所有True的词元数量\n",
    "\n",
    "    @staticmethod\n",
    "    # staticmethod 返回函数的静态方法 可以不实例化即可调用方法\n",
    "    def make_std_mask(tgt, pad):\n",
    "        \"\"\"\n",
    "        pad 和 future words 均在mask中用pad表示\n",
    "        \"\"\"\n",
    "        tgt_mask = (tgt != pad).unsqueeze(-2)\n",
    "        sequence_len = tgt.size(-1)  # 或是batch中最长时间步数\n",
    "        tgt_mask = tgt_mask & subsequent_mask(size=sequence_len).type_as(\n",
    "            tgt_mask.data\n",
    "            # &:进行位运算\n",
    "            # subsequent_mask()返回维度为(1, size, size)\n",
    "            # type_as():将数据类型转换为tgt_mask的数据类型\n",
    "        )\n",
    "        return tgt_mask\n",
    "\n",
    "\n",
    "# 5.2 Training Loop\n",
    "class TrainState:\n",
    "    \"\"\"\n",
    "    跟踪处理的步骤、示例和标记的数量\n",
    "    \"\"\"\n",
    "    step: int = 0  # 当前epoch的步\n",
    "    accum_step: int = 0  # 梯度累积步数\n",
    "    samples: int = 0  # 使用的示例总数\n",
    "    tokens: int = 0  # 处理的tokens总数\n",
    "\n",
    "\n",
    "def run_epoch(data_iter, model, loss_compute,\n",
    "              optimizer, scheduler,\n",
    "              mode=\"train\", accum_iter=1,\n",
    "              train_state=TrainState(),\n",
    "              device=None):\n",
    "    \"\"\"\n",
    "    完成了一个epoch训练的所有工作\n",
    "    包括数据加载、模型推理、损失计算与方向传播，同时将训练过程信息进行打印\n",
    "    \"\"\"\n",
    "    # 训练单个epoch\n",
    "    start = time.time()\n",
    "    total_tokens = 0\n",
    "    total_loss = 0\n",
    "    tokens = 0\n",
    "    n_accum = 0  # 梯度累积步数\n",
    "    for i, batch in enumerate(data_iter):\n",
    "        # model是一个EncoderDecoder对象\n",
    "        # 前向传播将src, src_mask传入编码函数，得到结果后与src_mask, tgt和tgt_mask一同传给解码函数\n",
    "        out = model.forward(src=batch.src, tgt=batch.tgt, src_mask=batch.src_mask, tgt_mask=batch.tgt_mask)\n",
    "        # 梯度累加技术 loss_node = loss_node / accum_iter\n",
    "        # accum_iter:小批次数 默认是1 不使用梯度累加技术\n",
    "        loss, loss_node = loss_compute(x=out, y=batch.tgt_y, norm=batch.ntokens)  # 计算损失->SimpleLossCompute\n",
    "        if mode == \"train\" or mode == \"train+log\":\n",
    "            loss_node.backward()  # 反向传播->不进行梯度清零, 执行梯度累加的操作\n",
    "            train_state.step += 1\n",
    "            train_state.samples += batch.src.shape[0]\n",
    "            train_state.tokens += batch.ntokens\n",
    "            if i % accum_iter == 0:  # 梯度累加达到固定次数之后\n",
    "                optimizer.step()  # 更新参数\n",
    "                optimizer.zero_grad(set_to_none=True)  # 梯度清零\n",
    "                n_accum += 1\n",
    "                train_state.accum_step += 1\n",
    "            scheduler.step()\n",
    "\n",
    "        total_loss += loss\n",
    "        total_tokens += batch.ntokens\n",
    "        tokens += batch.ntokens\n",
    "\n",
    "        if i % 40 == 1 and (mode == \"train\" or mode == \"train+log\"):\n",
    "            lr = optimizer.param_groups[0][\"lr\"]  # 获取学习率\n",
    "            elapsed = time.time() - start  # 计算40个迭代所需时间\n",
    "            print((\"Epoch Step: %6d | Accumulation Step: %3d | Loss: %6.2f \" +\n",
    "                   \"| Tokens / Sec: %7.1f | Learning Rate: %6.1e\") %\n",
    "                  (i, n_accum, loss / batch.ntokens, tokens / elapsed, lr))\n",
    "            start = time.time()\n",
    "            tokens = 0\n",
    "\n",
    "        del loss\n",
    "        del loss_node\n",
    "    return total_loss / total_tokens, train_state\n",
    "\n",
    "\n",
    "# 5.2 Optimizer\n",
    "def rate(step, model_size, factor, warmup):\n",
    "    \"\"\"\n",
    "    对于 Lambda LR 函数，我们必须将步骤默认为 1 避免零提升为负幂。\n",
    "    :param step: 时间步长\n",
    "    :param model_size: 模型维度\n",
    "    :param factor: 示例中为1\n",
    "    :param warmup: 预热迭代数\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if step == 0:\n",
    "        step = 1\n",
    "    return factor * (\n",
    "            model_size ** (-0.5) * min(step ** (-0.5), step * warmup ** (-1.5))\n",
    "    )\n",
    "\n",
    "\n",
    "def example_learning_schedule():\n",
    "    \"\"\"\n",
    "    学习率调度示例: 在 opts 列表中有 3 个示例。\n",
    "    为每个示例运行 20000 个 epoch\n",
    "    学习率调度使用 自定义调整学习率LambdaLR\n",
    "    数据可视化工具: Altair\n",
    "    \"\"\"\n",
    "    opts = [\n",
    "        [512, 1, 4000],  # example 1\n",
    "        [512, 1, 8000],  # example 2\n",
    "        [256, 1, 4000],  # example 3\n",
    "    ]\n",
    "    dummy_model = torch.nn.Linear(1, 1)\n",
    "    learning_rates = []\n",
    "\n",
    "    for idx, example in enumerate(opts):\n",
    "        optimizer = torch.optim.Adam(dummy_model.parameters(),\n",
    "                                     lr=1,\n",
    "                                     betas=(0.9, 0.98),\n",
    "                                     eps=1e-9)\n",
    "        lr_scheduler = LambdaLR(\n",
    "            optimizer=optimizer,\n",
    "            lr_lambda=lambda step: rate(step, *example))\n",
    "        tmp = []\n",
    "        #  采取20000次的虚拟训练步骤，并保存每一步的学习率\n",
    "        for step in range(20000):\n",
    "            # optimizer.param_groups[0]：长度为6的字典，\n",
    "            # 包括[‘amsgrad’, ‘params’, ‘lr’, ‘betas’, ‘weight_decay’, ‘eps’]\n",
    "            tmp.append(optimizer.param_groups[0][\"lr\"])\n",
    "            optimizer.step()  # 更新参数\n",
    "            lr_scheduler.step()  # 更新参数\n",
    "        learning_rates.append(tmp)\n",
    "\n",
    "    learning_rates = torch.tensor(learning_rates)\n",
    "    # ----数据可视化----\n",
    "    # 使 altair 能够处理超过 5000 行\n",
    "    alt.data_transformers.disable_max_rows()\n",
    "\n",
    "    opts_data = pd.concat(\n",
    "        [\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"Learning Rate\": learning_rates[warmup_idx, :],\n",
    "                    \"model_size:warmup\": [\"512:4000\", \"512:8000\", \"256:4000\"][\n",
    "                        warmup_idx\n",
    "                    ],\n",
    "                    \"step\": range(20000),\n",
    "                }\n",
    "            )\n",
    "            for warmup_idx in [0, 1, 2]\n",
    "        ]\n",
    "    )\n",
    "    return (\n",
    "        alt.Chart(opts_data)\n",
    "            .mark_line()\n",
    "            .properties(width=600)\n",
    "            .encode(x=\"step\", y=\"Learning Rate\", color=\"model_size:warmup:N\")\n",
    "            .interactive()\n",
    "    )\n",
    "\n",
    "\n",
    "# 5.3 Regularization\n",
    "\n",
    "# 5.3.2 Label Smoothing\n",
    "class LabelSmoothing(nn.Module):\n",
    "    def __init__(self, size, padding_idx, smoothing=0.0):\n",
    "        super(LabelSmoothing, self).__init__()\n",
    "        self.criterion = nn.KLDivLoss(reduction=\"sum\")\n",
    "        self.padding_idx = padding_idx\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.size = size\n",
    "        self.true_dist = None\n",
    "\n",
    "    def forward(self, x, target):\n",
    "        assert x.size(1) == self.size\n",
    "        true_dist = x.data.clone()\n",
    "        true_dist.fill_(self.smoothing / (self.size - 2))\n",
    "        true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        true_dist[:, self.padding_idx] = 0\n",
    "        mask = torch.nonzero(target.data == self.padding_idx)\n",
    "        if mask.dim() > 0:\n",
    "            true_dist.index_fill_(0, mask.squeeze(), 0.0)\n",
    "        self.true_dist = true_dist\n",
    "        return self.criterion(x, true_dist.clone().detach())\n",
    "\n",
    "\n",
    "RUN_EXAMPLES = True\n",
    "\n",
    "\n",
    "def show_example(fn, args=[]):\n",
    "    if __name__ == \"__main__\" and RUN_EXAMPLES:\n",
    "        return fn(*args)\n",
    "\n",
    "\n",
    "def example_label_smoothing():\n",
    "    crit = LabelSmoothing(5, 0, 0.4)\n",
    "    predict = torch.FloatTensor(\n",
    "        [\n",
    "            [0, 0.2, 0.7, 0.1, 0],\n",
    "            [0, 0.2, 0.7, 0.1, 0],\n",
    "            [0, 0.2, 0.7, 0.1, 0],\n",
    "            [0, 0.2, 0.7, 0.1, 0],\n",
    "            [0, 0.2, 0.7, 0.1, 0],\n",
    "        ]\n",
    "    )\n",
    "    crit(x=predict.log(), target=torch.LongTensor([2, 1, 0, 3, 3]))\n",
    "    LS_data = pd.concat(\n",
    "        [\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"target distribution\": crit.true_dist[x, y].flatten(),\n",
    "                    \"columns\": y,\n",
    "                    \"rows\": x,\n",
    "                }\n",
    "            )\n",
    "            for y in range(5)\n",
    "            for x in range(5)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        alt.Chart(LS_data)\n",
    "            .mark_rect(color=\"Blue\", opacity=1)\n",
    "            .properties(height=200, width=200)\n",
    "            .encode(\n",
    "            alt.X(\"columns:O\", title=None),\n",
    "            alt.Y(\"rows:O\", title=None),\n",
    "            alt.Color(\n",
    "                \"target distribution:Q\", scale=alt.Scale(scheme=\"viridis\")\n",
    "            ),\n",
    "        )\n",
    "            .interactive()\n",
    "    )\n",
    "\n",
    "\n",
    "def loss(x, crit):\n",
    "    d = x + 3 * 1\n",
    "    predict = torch.FloatTensor([[0, x / d, 1 / d, 1 / d, 1 / d]])\n",
    "    return crit(predict.log(), torch.LongTensor([1])).data\n",
    "\n",
    "\n",
    "def penalization_visualization():\n",
    "    crit = LabelSmoothing(5, 0, 0.1)\n",
    "    loss_data = pd.DataFrame({\n",
    "        \"Loss\": [loss(x, crit) for x in range(1, 100)],\n",
    "        \"Steps\": list(range(99)),\n",
    "    }).astype(\"float\")\n",
    "\n",
    "    return (alt.Chart(loss_data).mark_line().properties(width=350).encode(\n",
    "        x=\"Steps\",\n",
    "        y=\"Loss\",\n",
    "    ).interactive())\n",
    "\n",
    "\n",
    "# 6 A First Example\n",
    "\n",
    "# 6.1 Synthetic Data\n",
    "def data_gen(V, n_batches, batch_size, s_len=10, device=None):\n",
    "    \"\"\"\n",
    "    <编码器-解码器数据复制任务> 随机数据生成器\n",
    "    :param device: 是否使用GPU加速\n",
    "    :param V: 词典数量，取值范围[0, V-1]，约定0作为特殊符号使用代表padding\n",
    "    :param batch_size: 批次大小\n",
    "    :param n_batches: 需要生成的批次数量\n",
    "    :param s_len: 生成的序列数据的长度\n",
    "    \"\"\"\n",
    "    for i in range(n_batches):\n",
    "        src_data = torch.randint(2, V, size=(batch_size, s_len))\n",
    "        # 约定输出为输入除去序列第一个元素，即向后平移一位进行输出，同时输出数据要在第一个时间步添加一个起始符\n",
    "        tgt_data = src_data.clone()\n",
    "        tgt_data[:, 0] = 1  # 将序列的第一个时间步置为1(即约定的起始符)\n",
    "        # .batch()\n",
    "        # 返回一个新的tensor，从当前计算图中分离下来的，但是仍指向原变量的存放位置\n",
    "        # 不同之处只是requires_grad为false，得到的这个tensor永远不需要计算其梯度，不具有grad。\n",
    "        # requires_grad 默认为False\n",
    "        src = src_data.requires_grad_(False).clone().detach()\n",
    "        tgt = tgt_data.requires_grad_(False).clone().detach()\n",
    "        if device == \"cuda\":\n",
    "            src = src.cuda()\n",
    "            tgt = tgt.cuda()\n",
    "        yield Batch(src=src, tgt=tgt, pad=0)\n",
    "\n",
    "\n",
    "# 6.2 Loss Computation\n",
    "class SimpleLossCompute:\n",
    "    def __init__(self, generator, criterion):\n",
    "        self.generator = generator\n",
    "        self.criterion = criterion  # 使用标签平滑\n",
    "\n",
    "    def __call__(self, x, y, norm):\n",
    "        \"\"\"\n",
    "        :param x: decoder输出的结果\n",
    "        :param y: 标签数据\n",
    "        :param norm: loss的归一化系数，用batch中所有有效token数即可\n",
    "        \"\"\"\n",
    "        x = self.generator(x)\n",
    "        # contiguous():\n",
    "        # 1. 由于torch.view等方法操作需要连续的Tensor\n",
    "        # 2. 出于性能考虑 使用该方法后会重新据开辟一块内存空间保证数是在逻辑顺序和内存中是一致的\n",
    "        x_ = x.contiguous().view(-1, x.size(-1))\n",
    "        y_ = y.contiguous().view(-1)\n",
    "        loss = self.criterion(x_, y_)\n",
    "        sloss = (loss / norm)\n",
    "\n",
    "        return sloss.data * norm, loss\n",
    "\n",
    "\n",
    "# 6.3 Greedy Decoding\n",
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    # encoder()编码函数: 使用src_embed对src做处理，然后和src_mask一起传给self.encoder\n",
    "    memory = model.encode(src=src, src_mask=src_mask)\n",
    "    # ys代表目前已生成的序列，最初为仅包含一个起始符的序列，不断将预测结果追加到序列最后\n",
    "    ys = torch.zeros(1, 1).fill_(start_symbol).type_as(src.data)\n",
    "    for i in range(max_len - 1):\n",
    "        # decoder()解码函数: 使用tgt_embed对tgt做处理，然后和src_mask, tgt_mask, memory一起传给self.decoder\n",
    "        out = model.decode(memory=memory,\n",
    "                           src_mask=src_mask,\n",
    "                           tgt=ys,\n",
    "                           tgt_mask=subsequent_mask(size=ys.size(1)).type_as(src.data))\n",
    "        # generator: 类别生成器对象 -> linear+softmax\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.data[0]\n",
    "        # cat(): 实现拼接操作\n",
    "        ys = torch.cat(\n",
    "            [ys, torch.zeros(1, 1).type_as(src.data).fill_(next_word)],\n",
    "            dim=1)\n",
    "    return ys\n",
    "\n",
    "\n",
    "# 6.4 Training Example\n",
    "# def execute_example(fn, args=[]):\n",
    "#     if __name__ == \"__main__\" and RUN_EXAMPLES:\n",
    "#         fn(*args)\n",
    "\n",
    "\n",
    "class DummyOptimizer(torch.optim.Optimizer):\n",
    "    def __init__(self):\n",
    "        self.param_groups = [{\"lr\": 0}]\n",
    "        None\n",
    "\n",
    "    def step(self):\n",
    "        None\n",
    "\n",
    "    def zero_grad(self, set_to_none=False):\n",
    "        None\n",
    "\n",
    "\n",
    "class DummyScheduler:\n",
    "    def step(self):\n",
    "        None\n",
    "\n",
    "\n",
    "def example_simple_model(device=None):\n",
    "    V = 11  # 字典的大小\n",
    "    criterion = LabelSmoothing(size=V, padding_idx=0, smoothing=0.0)\n",
    "    model = make_model(src_vocab=V, tgt_vocab=V, N=2)\n",
    "    if device == \"cuda\":\n",
    "        model.cuda()\n",
    "    model_size = model.src_embed[0].d_model  # 512\n",
    "\n",
    "    n_epochs = 20\n",
    "    n_batch_train_epoch = 20  # 训练时每个epoch所需批次大小\n",
    "    n_batch_val_epoch = 5  # 验证时每个epoch所需批次大小\n",
    "    batch_size = 80\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                 lr=0.5,\n",
    "                                 betas=(0.9, 0.98),\n",
    "                                 eps=1e-9)\n",
    "    lr_scheduler = LambdaLR(\n",
    "        optimizer=optimizer,\n",
    "        lr_lambda=lambda step: rate(step=step, model_size=model_size, factor=0.1, warmup=400)\n",
    "    )\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        loss_compute = SimpleLossCompute(generator=model.generator,\n",
    "                                         criterion=criterion)\n",
    "\n",
    "        print(f\"\\n|   批次: {epoch}   |\")\n",
    "        print(\"*\" * 5 + \"训练\" + \"*\" * 5)\n",
    "        model.train()  # self.training=True\n",
    "\n",
    "        train_data_iter = data_gen(V=V, n_batches=n_batch_train_epoch,\n",
    "                                   batch_size=batch_size, device=device)\n",
    "        run_epoch(data_iter=train_data_iter,\n",
    "                  model=model,\n",
    "                  loss_compute=loss_compute,\n",
    "                  optimizer=optimizer,\n",
    "                  scheduler=lr_scheduler,\n",
    "                  mode=\"train\")\n",
    "\n",
    "        # -----------\n",
    "        print(\"*\" * 5 + \"验证\" + \"*\" * 5)\n",
    "        model.eval()  # self.training=False\n",
    "\n",
    "        val_data_iter = data_gen(V=V, n_batches=n_batch_val_epoch,\n",
    "                                 batch_size=batch_size, device=device)\n",
    "        valid_mean_loss = run_epoch(data_iter=val_data_iter,\n",
    "                                    model=model,\n",
    "                                    loss_compute=loss_compute,\n",
    "                                    optimizer=DummyOptimizer(),  # None\n",
    "                                    scheduler=DummyScheduler(),  # None\n",
    "                                    mode=\"eval\")[0]  # 返回: total_loss / total_tokens\n",
    "        print(f\"|验证损失: {valid_mean_loss} |\")\n",
    "\n",
    "    model.eval()\n",
    "    torch.save(model, './models/Pytorch/example_1_copy.pth')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd77fe03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-16T16:07:23.098866Z",
     "iopub.status.busy": "2022-05-16T16:07:23.098643Z",
     "iopub.status.idle": "2022-05-16T16:07:32.449644Z",
     "shell.execute_reply": "2022-05-16T16:07:32.448746Z"
    },
    "papermill": {
     "duration": 9.363989,
     "end_time": "2022-05-16T16:07:32.452203",
     "exception": false,
     "start_time": "2022-05-16T16:07:23.088214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: GPUtil in /opt/conda/lib/python3.7/site-packages (1.4.0)\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install GPUtil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9243f963",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-16T16:07:32.476192Z",
     "iopub.status.busy": "2022-05-16T16:07:32.475956Z",
     "iopub.status.idle": "2022-05-16T16:07:41.302987Z",
     "shell.execute_reply": "2022-05-16T16:07:41.302132Z"
    },
    "papermill": {
     "duration": 8.84156,
     "end_time": "2022-05-16T16:07:41.305165",
     "exception": false,
     "start_time": "2022-05-16T16:07:32.463605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# ----\n",
    "from torchtext import data, datasets\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import torch.multiprocessing as mp\n",
    "import GPUtil\n",
    "import spacy\n",
    "import os\n",
    "from os.path import exists\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 1. 加载德文，英文分词器\n",
    "def load_tokenizers():\n",
    "    try:\n",
    "        spacy_de = spacy.load(\"de_core_news_sm\")\n",
    "    except IOError:\n",
    "        os.system(\"python -m spacy download de_core_news_sm\")\n",
    "        spacy_de = spacy.load(\"de_core_news_sm\")\n",
    "\n",
    "    try:\n",
    "        spacy_en = spacy.load(\"en_core_web_sm\")\n",
    "    except IOError:\n",
    "        os.system(\"python -m spacy download en_core_web_sm\")\n",
    "        spacy_en = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    return spacy_de, spacy_en\n",
    "\n",
    "\n",
    "# 2. 分词\n",
    "def tokenize(text, tokenizer):\n",
    "    \"\"\"\n",
    "    分词处理\n",
    "    Spacy 会先将文档分解成句子，然后再 tokenize 。我们可以使用迭代来遍历整个文档\n",
    "    :param text: 文本\n",
    "    :param tokenizer: 分词器 spacy_zh 或 spacy_en\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return [token.text for token in tokenizer.tokenizer(text)]\n",
    "\n",
    "\n",
    "def yield_tokens(data_iter, tokenizer, index):\n",
    "    # index[0]:德文 index[1]:英文\n",
    "    for from_to_tuple in data_iter:\n",
    "        yield tokenizer(from_to_tuple[index])\n",
    "\n",
    "\n",
    "# 3. 构建词汇表\n",
    "def build_vocabulary(spacy_de, spacy_en):\n",
    "    \"\"\"\n",
    "    构建数据集\n",
    "    - 使用torchtext自带的机器翻译数据集 Multi30k\n",
    "        -- language_pair:指定使用的翻译句子对的语言，默认是从德语到英语。数据集中的每一行是一对指定语言的句子对\n",
    "    - build_vocab_from_iterator() :从迭代器构建词汇函数\n",
    "        -- iterator: 构建 Vocab 的迭代器\n",
    "        -- min_freq: 在词汇表中包含标记所需的最小频率\n",
    "        -- specials: 要添加的特殊符号\n",
    "    \"\"\"\n",
    "    BOS_WORD = '<s>'  # beginning of sequence 序列开始标识\n",
    "    EOS_WORD = '</s>'  # end of sequence 序列结束标识\n",
    "    BLANK_WORD = '<blank>'  # 空白标识\n",
    "    UNK_WORD = '<unk>'  # 未知字符标识\n",
    "\n",
    "    def tokenize_de(text):\n",
    "        return tokenize(text=text, tokenizer=spacy_de)\n",
    "\n",
    "    def tokenize_en(text):\n",
    "        return tokenize(text=text, tokenizer=spacy_en)\n",
    "\n",
    "    print(\"***构建德文数据集***\")\n",
    "    train, val, test = datasets.Multi30k(language_pair=(\"de\", \"en\"))\n",
    "    vocab_src = build_vocab_from_iterator(\n",
    "        iterator=yield_tokens(\n",
    "            data_iter=train + val + test,\n",
    "            tokenizer=tokenize_de,\n",
    "            index=0\n",
    "        ),\n",
    "        min_freq=2,\n",
    "        specials=[BOS_WORD, EOS_WORD, BLANK_WORD, UNK_WORD]\n",
    "    )\n",
    "\n",
    "    print(\"***构建英文数据集***\")\n",
    "    train, val, test = datasets.Multi30k(language_pair=(\"de\", \"en\"))\n",
    "    vocab_tgt = build_vocab_from_iterator(\n",
    "        iterator=yield_tokens(\n",
    "            data_iter=train + val + test,\n",
    "            tokenizer=tokenize_en,\n",
    "            index=1\n",
    "        ),\n",
    "        min_freq=2,\n",
    "        specials=[BOS_WORD, EOS_WORD, BLANK_WORD, UNK_WORD]\n",
    "    )\n",
    "\n",
    "    vocab_src.set_default_index(vocab_src[UNK_WORD])\n",
    "    vocab_tgt.set_default_index(vocab_src[UNK_WORD])\n",
    "\n",
    "    return vocab_src, vocab_tgt\n",
    "\n",
    "\n",
    "vocab_path = \"./vocab.pt\"\n",
    "\n",
    "\n",
    "def load_vocab(spacy_de, spacy_en, vocab_path):\n",
    "    if not exists(vocab_path):\n",
    "        vocab_src, vocab_tgt = build_vocabulary(spacy_de, spacy_en)\n",
    "        torch.save((vocab_src, vocab_tgt), vocab_path)\n",
    "        print(\"完成构建!\")\n",
    "    else:\n",
    "        vocab_src, vocab_tgt = torch.load(vocab_path)\n",
    "        print(\"完成加载!\")\n",
    "    print(\"德文词汇量：\" + str(len(vocab_src)))\n",
    "    print(\"英文词汇量：\" + str(len(vocab_tgt)))\n",
    "    return vocab_src, vocab_tgt\n",
    "\n",
    "\n",
    "# 4. 迭代器\n",
    "def collate_batch(batch, src_pipeline, tgt_pipeline, src_vocab, tgt_vocab, device, max_padding=128, PAD_id=2):\n",
    "    \"\"\"\n",
    "    批次数据整理:标识开始结束token 并进行填充至统一长度\n",
    "    :param batch:\n",
    "    :param src_pipeline: 输入分词器-tokenize_de\n",
    "    :param tgt_pipeline: 目标分词器-tokenize_en\n",
    "    :param src_vocab: 输入词汇表-vocab_src\n",
    "    :param tgt_vocab: 输出词汇表-vocab_tgt\n",
    "    :param device: 使用GPU加速\n",
    "    :param max_padding: 最大填充默认128\n",
    "    :param PAD_id: 填充id -> <black> 空白标识\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    BOS_id = torch.tensor([0], device=device)  # <s>  序列开始标识ID\n",
    "    EOS_id = torch.tensor([1], device=device)  # </s> 序列结束标识ID\n",
    "    src_list, tgt_list = [], []\n",
    "    for (_src, _tgt) in batch:\n",
    "        # 对输入批次进行预处理 添加序列开始和结束标识\n",
    "        processed_src = torch.cat(\n",
    "            [\n",
    "                BOS_id,  # <s>\n",
    "                torch.tensor(\n",
    "                    src_vocab(src_pipeline(_src)),\n",
    "                    dtype=torch.int64,\n",
    "                    device=device,\n",
    "                ),\n",
    "                EOS_id,  # </s>\n",
    "            ],\n",
    "            dim=0,\n",
    "        )\n",
    "        # 对目标批次进行预处理\n",
    "        processed_tgt = torch.cat(\n",
    "            [\n",
    "                BOS_id,  # <s>\n",
    "                torch.tensor(\n",
    "                    tgt_vocab(tgt_pipeline(_tgt)),\n",
    "                    dtype=torch.int64,\n",
    "                    device=device,\n",
    "                ),\n",
    "                EOS_id,  # </s>\n",
    "            ],\n",
    "            dim=0,\n",
    "        )\n",
    "\n",
    "        # F.pad 通过填充较短的序列来处理，以便批次中的所有序列具有相同的长度\n",
    "        src_list.append(\n",
    "            F.pad(\n",
    "                input=processed_src,\n",
    "                pad=(0, max_padding - len(processed_src)),  # (0, 128-len(processed_src))\n",
    "                mode=\"constant\",\n",
    "                value=PAD_id,\n",
    "            ))\n",
    "        tgt_list.append(\n",
    "            F.pad(\n",
    "                input=processed_tgt,\n",
    "                pad=(0, max_padding - len(processed_tgt)),\n",
    "                mode=\"constant\",\n",
    "                value=PAD_id,\n",
    "            ))\n",
    "\n",
    "    # stack(): 对张量序列进行连接\n",
    "    src = torch.stack(src_list)\n",
    "    tgt = torch.stack(tgt_list)\n",
    "\n",
    "    return (src, tgt)\n",
    "\n",
    "\n",
    "def create_dataloaders(device, vocab_src, vocab_tgt, spacy_de, spacy_en, batch_size=12000, max_padding=128,\n",
    "                       is_distributed=True):\n",
    "    \"\"\"\n",
    "    创建数据加载器\n",
    "    :param spacy_de: 德文分词器\n",
    "    :param spacy_en: 英文分词器\n",
    "    :param batch_size: 批次大小为12000\n",
    "    :param is_distributed: 是否使用分布式训练\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    def tokenize_de(text):\n",
    "        return tokenize(text=text, tokenizer=spacy_de)\n",
    "\n",
    "    def tokenize_en(text):\n",
    "        return tokenize(text=text, tokenizer=spacy_en)\n",
    "\n",
    "    def collate_fn(batch):\n",
    "        return collate_batch(\n",
    "            batch=batch,\n",
    "            src_pipeline=tokenize_de,\n",
    "            tgt_pipeline=tokenize_en,\n",
    "            src_vocab=vocab_src,\n",
    "            tgt_vocab=vocab_tgt,\n",
    "            device=device,\n",
    "            max_padding=max_padding,\n",
    "            # get_stoi(): 字典将标记映射到索引\n",
    "            PAD_id=vocab_src.get_stoi()[\"<blank>\"],  # 2\n",
    "        )\n",
    "\n",
    "    train_iter, valid_iter, test_iter = datasets.Multi30k(language_pair=(\"de\", \"en\"))\n",
    "\n",
    "    # 1. 转换数据集类型为map-style\n",
    "    #   - to_map_style_dataset(): 将`iterable-style`数据集转换为`map-style`数据集。\n",
    "    #       - `map-style`是使用索引/键向数据样本进行映射\n",
    "    #       - `iterable-style`的迭代型的数据集就是真正载入数据\n",
    "    train_iter_map = to_map_style_dataset(train_iter)\n",
    "    valid_iter_map = to_map_style_dataset(valid_iter)\n",
    "\n",
    "    # 2. 使用分布式采样器\n",
    "    #   - DistributedSampler(): 分布式采样器  由于使用多GPU训练 加载策略是负责只提供加载数据集中的一个子集\n",
    "    #       - 使用分布式采样器需要数据集的len()\n",
    "    train_sampler = (\n",
    "        DistributedSampler(dataset=train_iter_map) if is_distributed else None\n",
    "    )\n",
    "    valid_sampler = (\n",
    "        DistributedSampler(dataset=valid_iter_map) if is_distributed else None\n",
    "    )\n",
    "\n",
    "    # 3. 创建数据加载器： 使用DataLoader()结合数据集和采样器，并提供可迭代的给定的数据集。\n",
    "    train_dataloader = DataLoader(\n",
    "        dataset=train_iter_map,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=(train_sampler is None),  # 如果未指定采样器则进行混洗\n",
    "        sampler=train_sampler,\n",
    "        collate_fn=collate_fn,  # 在使用批量加载`map-style`数据集时使用 批次数据整理\n",
    "    )\n",
    "    valid_dataloader = DataLoader(\n",
    "        dataset=valid_iter_map,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=(valid_sampler is None),\n",
    "        sampler=valid_sampler,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "    return train_dataloader, valid_dataloader\n",
    "\n",
    "\n",
    "# 5. 多 GPU 训练\n",
    "\n",
    "def train_worker(gpu, ngpus_per_node, vocab_src, vocab_tgt, spacy_de, spacy_en, config, is_distributed=False):\n",
    "    \"\"\"\n",
    "    配置训练任务\n",
    "    :param gpu: 主机编号\n",
    "    :param ngpus_per_node: 主机数量\n",
    "    :param config: 参数配置\n",
    "    :param is_distributed: 是否使用分布式训练\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # ----多卡配置----\n",
    "    print(f\"使用 GPU 训练工作进程： {gpu} 训练\", flush=True)\n",
    "    torch.cuda.set_device(gpu)\n",
    "\n",
    "    pad_idx = vocab_tgt[\"<blank>\"]  # 空白填充token的id\n",
    "    d_model = 512\n",
    "    model = make_model(len(vocab_src), len(vocab_tgt), N=6)\n",
    "    model.cuda(gpu)\n",
    "    module = model\n",
    "    is_main_process = True\n",
    "\n",
    "    if is_distributed:\n",
    "        \"\"\"\n",
    "        torch.distributed库: 实现单机多卡训练库\n",
    "        - init_process_group(): 初始化默认的分布式进程组\n",
    "           - backend: 一般来说使用NCCL对于GPU分布式训练，使用gloo对CPU进行分布式训练\n",
    "           - init_method: URL指定了如何初始化互相通信的进程    \n",
    "           - rank: 优先度或gpu的编号/进程的编号 rank=0的主机就是主要节点\n",
    "           - world_size: 执行训练的所有的进程数/GPU数\n",
    "        - DistributedDataParallel(): DDP模式: 使用多进程；性能更优；模型广播只在初始化的时候, 故训练加速\n",
    "        \"\"\"\n",
    "        dist.init_process_group(\n",
    "            backend=\"nccl\",\n",
    "            init_method=\"env://\",\n",
    "            rank=gpu,\n",
    "            world_size=ngpus_per_node\n",
    "        )\n",
    "        model = DDP(module=model, device_ids=[gpu])\n",
    "        module = model.module\n",
    "        is_main_process = gpu == 0\n",
    "\n",
    "    # ----训练配置----\n",
    "    criterion = LabelSmoothing(\n",
    "        size=len(vocab_tgt), padding_idx=pad_idx, smoothing=0.1\n",
    "    )\n",
    "    criterion.cuda(gpu)\n",
    "    # 创建数据加载器\n",
    "    train_dataloader, valid_dataloader = create_dataloaders(\n",
    "        gpu,\n",
    "        vocab_src,\n",
    "        vocab_tgt,\n",
    "        spacy_de,\n",
    "        spacy_en,\n",
    "        batch_size=config[\"batch_size\"] // ngpus_per_node,  # 批次大小 // 总GPU数\n",
    "        max_padding=config[\"max_padding\"],\n",
    "        is_distributed=is_distributed,\n",
    "    )\n",
    "    # 优化器\n",
    "    optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                 lr=config[\"base_lr\"],\n",
    "                                 betas=(0.9, 0.98),\n",
    "                                 eps=1e-9)\n",
    "    # 学习率调度\n",
    "    lr_scheduler = LambdaLR(\n",
    "        optimizer=optimizer,\n",
    "        lr_lambda=lambda step: rate(step, d_model, factor=1, warmup=config[\"warmup\"]),\n",
    "    )\n",
    "    train_state = TrainState()  # 跟踪处理的步骤、示例和标记的数量\n",
    "\n",
    "    for epoch in range(config[\"num_epochs\"]):\n",
    "        if is_distributed:  # 使用分布式训练就需要进行分批操作\n",
    "            train_dataloader.sampler.set_epoch(epoch)\n",
    "            valid_dataloader.sampler.set_epoch(epoch)\n",
    "\n",
    "        print(f\"\\n|   批次: {epoch}   |\")\n",
    "        print(\"*\" * 5 + \"训练\" + \"*\" * 5)\n",
    "        model.train()\n",
    "        print(f\"[GPU{gpu}] Epoch {epoch} Training ====\", flush=True)\n",
    "        train_data_iter = (Batch(src=b[0], tgt=b[1], pad=pad_idx) for b in train_dataloader)  #######\n",
    "        _, train_state = run_epoch(\n",
    "            data_iter=train_data_iter,\n",
    "            model=model,\n",
    "            loss_compute=SimpleLossCompute(module.generator, criterion),\n",
    "            optimizer=optimizer,\n",
    "            scheduler=lr_scheduler,\n",
    "            mode=\"train+log\",\n",
    "            accum_iter=config[\"accum_iter\"],\n",
    "            train_state=train_state,\n",
    "        )\n",
    "\n",
    "        GPUtil.showUtilization()  # 实时查看GPU状况\n",
    "        # 保存检查点模型\n",
    "        if is_main_process:\n",
    "            file_path = \"%s%.2d.pt\" % (config[\"file_prefix\"], epoch)\n",
    "            torch.save(module.state_dict(), file_path)\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # -----------\n",
    "        print(\"*\" * 5 + \"验证\" + \"*\" * 5)\n",
    "        print(f\"[GPU{gpu}] Epoch {epoch} Validation ====\", flush=True)\n",
    "        model.eval()\n",
    "        valid_data_iter = (Batch(src=b[0], tgt=b[1], pad=pad_idx) for b in valid_dataloader)  ######\n",
    "        valid_mean_loss = run_epoch(\n",
    "            data_iter=valid_data_iter,\n",
    "            model=model,\n",
    "            loss_compute=SimpleLossCompute(module.generator, criterion),\n",
    "            optimizer=DummyOptimizer(),\n",
    "            scheduler=DummyScheduler(),\n",
    "            mode=\"eval\",\n",
    "        )\n",
    "        print(valid_mean_loss)\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # 保存最终模型\n",
    "    if is_main_process:\n",
    "        file_path = \"%sfinal.pt\" % config[\"file_prefix\"]\n",
    "        torch.save(module.state_dict(), file_path)\n",
    "\n",
    "\n",
    "def train_distributed_model(vocab_src, vocab_tgt, spacy_de, spacy_en, config):\n",
    "    \"\"\"\n",
    "    配置分布式训练任务\n",
    "    \"\"\"\n",
    "    ngpus = torch.cuda.device_count()\n",
    "    os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "    os.environ[\"MASTER_PORT\"] = \"12356\"\n",
    "    print(f\"检测到的 GPUs 数量： {ngpus}\")\n",
    "    print(\"产生训练过程中 ...\")\n",
    "\n",
    "    # torch.multiprocessing(): 实现pytorch多进程\n",
    "    mp.spawn(\n",
    "        fn=train_worker,\n",
    "        nprocs=ngpus,\n",
    "        args=(ngpus, vocab_src, vocab_tgt, spacy_de, spacy_en, config, True),\n",
    "    )\n",
    "\n",
    "\n",
    "def train_model(vocab_src, vocab_tgt, spacy_de, spacy_en, config):\n",
    "    \"\"\"\n",
    "    选择训练任务的训练类型\n",
    "    \"\"\"\n",
    "    if config[\"distributed\"]:  # 执行分布式训练\n",
    "        train_distributed_model(\n",
    "            vocab_src, vocab_tgt, spacy_de, spacy_en, config\n",
    "        )\n",
    "    else:   # 执行单GPU训练\n",
    "        train_worker(\n",
    "            gpu=0,\n",
    "            ngpus_per_node=1,\n",
    "            vocab_src=vocab_src,\n",
    "            vocab_tgt=vocab_tgt,\n",
    "            spacy_de=spacy_de,\n",
    "            spacy_en=spacy_en,\n",
    "            config=config,\n",
    "            is_distributed=False\n",
    "        )\n",
    "\n",
    "\n",
    "def load_trained_model():\n",
    "    config = {\n",
    "        \"batch_size\": 32,\n",
    "        \"distributed\": False,\n",
    "        \"num_epochs\": 8,\n",
    "        \"accum_iter\": 10,\n",
    "        \"base_lr\": 1.0,\n",
    "        \"max_padding\": 72,\n",
    "        \"warmup\": 3000,\n",
    "        \"file_prefix\": \"multi30k_model_\",\n",
    "    }\n",
    "    model_path = \"multi30k_model_final.pt\"\n",
    "    if not exists(model_path):\n",
    "        train_model(vocab_src, vocab_tgt, spacy_de, spacy_en, config)\n",
    "\n",
    "    model = make_model(len(vocab_src), len(vocab_tgt), N=6)\n",
    "    model.load_state_dict(torch.load(\"multi30k_model_final.pt\"))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5628bba4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-16T16:07:41.330824Z",
     "iopub.status.busy": "2022-05-16T16:07:41.329435Z",
     "iopub.status.idle": "2022-05-16T16:28:09.367778Z",
     "shell.execute_reply": "2022-05-16T16:28:09.366914Z"
    },
    "papermill": {
     "duration": 1228.053151,
     "end_time": "2022-05-16T16:28:09.370115",
     "exception": false,
     "start_time": "2022-05-16T16:07:41.316964",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting de-core-news-sm==3.2.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.2.0/de_core_news_sm-3.2.0-py3-none-any.whl (19.1 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 19.1/19.1 MB 20.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.3.0,>=3.2.0 in /opt/conda/lib/python3.7/site-packages (from de-core-news-sm==3.2.0) (3.2.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (2.0.7)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (4.63.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (1.21.6)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (0.4.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (0.7.7)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (3.3.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (1.8.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (2.27.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (21.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (3.0.6)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (1.0.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /opt/conda/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (2.4.3)\n",
      "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (3.10.0.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (0.9.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (59.8.0)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /opt/conda/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (8.0.15)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (3.1.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (1.0.7)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /opt/conda/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (3.0.9)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /opt/conda/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (0.6.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (3.7.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (3.0.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (5.2.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (2.0.12)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.7/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2->spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (2.0.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click<9.0.0,>=7.1.1->typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (4.11.3)\n",
      "Installing collected packages: de-core-news-sm\n",
      "Successfully installed de-core-news-sm-3.2.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('de_core_news_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***构建德文数据集***\n",
      "***构建英文数据集***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/datapipes/iter/combining.py:181: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n",
      "  \"the buffer and each child DataPipe will read from the start again.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完成构建!\n",
      "德文词汇量：8315\n",
      "英文词汇量：6384\n",
      "使用 GPU 训练工作进程： 0 训练\n",
      "\n",
      "|   批次: 0   |\n",
      "*****训练*****\n",
      "[GPU0] Epoch 0 Training ====\n",
      "Epoch Step:      1 | Accumulation Step:   1 | Loss:   7.58 | Tokens / Sec:   825.4 | Learning Rate: 5.4e-07\n",
      "Epoch Step:     41 | Accumulation Step:   5 | Loss:   7.36 | Tokens / Sec:  2880.7 | Learning Rate: 1.1e-05\n",
      "Epoch Step:     81 | Accumulation Step:   9 | Loss:   6.98 | Tokens / Sec:  2856.0 | Learning Rate: 2.2e-05\n",
      "Epoch Step:    121 | Accumulation Step:  13 | Loss:   6.71 | Tokens / Sec:  2825.3 | Learning Rate: 3.3e-05\n",
      "Epoch Step:    161 | Accumulation Step:  17 | Loss:   6.45 | Tokens / Sec:  2841.8 | Learning Rate: 4.4e-05\n",
      "Epoch Step:    201 | Accumulation Step:  21 | Loss:   6.38 | Tokens / Sec:  2801.3 | Learning Rate: 5.4e-05\n",
      "Epoch Step:    241 | Accumulation Step:  25 | Loss:   6.23 | Tokens / Sec:  2863.9 | Learning Rate: 6.5e-05\n",
      "Epoch Step:    281 | Accumulation Step:  29 | Loss:   5.95 | Tokens / Sec:  2808.8 | Learning Rate: 7.6e-05\n",
      "Epoch Step:    321 | Accumulation Step:  33 | Loss:   5.81 | Tokens / Sec:  2841.6 | Learning Rate: 8.7e-05\n",
      "Epoch Step:    361 | Accumulation Step:  37 | Loss:   5.47 | Tokens / Sec:  2853.7 | Learning Rate: 9.7e-05\n",
      "Epoch Step:    401 | Accumulation Step:  41 | Loss:   5.35 | Tokens / Sec:  2832.0 | Learning Rate: 1.1e-04\n",
      "Epoch Step:    441 | Accumulation Step:  45 | Loss:   5.07 | Tokens / Sec:  2776.3 | Learning Rate: 1.2e-04\n",
      "Epoch Step:    481 | Accumulation Step:  49 | Loss:   4.94 | Tokens / Sec:  2829.5 | Learning Rate: 1.3e-04\n",
      "Epoch Step:    521 | Accumulation Step:  53 | Loss:   4.84 | Tokens / Sec:  2819.0 | Learning Rate: 1.4e-04\n",
      "Epoch Step:    561 | Accumulation Step:  57 | Loss:   4.54 | Tokens / Sec:  2813.4 | Learning Rate: 1.5e-04\n",
      "Epoch Step:    601 | Accumulation Step:  61 | Loss:   4.47 | Tokens / Sec:  2829.4 | Learning Rate: 1.6e-04\n",
      "Epoch Step:    641 | Accumulation Step:  65 | Loss:   4.56 | Tokens / Sec:  2811.0 | Learning Rate: 1.7e-04\n",
      "Epoch Step:    681 | Accumulation Step:  69 | Loss:   4.28 | Tokens / Sec:  2828.3 | Learning Rate: 1.8e-04\n",
      "Epoch Step:    721 | Accumulation Step:  73 | Loss:   4.12 | Tokens / Sec:  2836.7 | Learning Rate: 1.9e-04\n",
      "Epoch Step:    761 | Accumulation Step:  77 | Loss:   4.28 | Tokens / Sec:  2845.6 | Learning Rate: 2.0e-04\n",
      "Epoch Step:    801 | Accumulation Step:  81 | Loss:   4.15 | Tokens / Sec:  2821.5 | Learning Rate: 2.2e-04\n",
      "Epoch Step:    841 | Accumulation Step:  85 | Loss:   4.12 | Tokens / Sec:  2843.6 | Learning Rate: 2.3e-04\n",
      "Epoch Step:    881 | Accumulation Step:  89 | Loss:   4.08 | Tokens / Sec:  2850.2 | Learning Rate: 2.4e-04\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 60% | 26% |\n",
      "*****验证*****\n",
      "[GPU0] Epoch 0 Validation ====\n",
      "(tensor(3.9669, device='cuda:0'), <__main__.TrainState object at 0x7f5210239c10>)\n",
      "\n",
      "|   批次: 1   |\n",
      "*****训练*****\n",
      "[GPU0] Epoch 1 Training ====\n",
      "Epoch Step:      1 | Accumulation Step:   1 | Loss:   4.16 | Tokens / Sec:  3167.9 | Learning Rate: 2.4e-04\n",
      "Epoch Step:     41 | Accumulation Step:   5 | Loss:   3.97 | Tokens / Sec:  2784.8 | Learning Rate: 2.6e-04\n",
      "Epoch Step:     81 | Accumulation Step:   9 | Loss:   4.04 | Tokens / Sec:  2796.5 | Learning Rate: 2.7e-04\n",
      "Epoch Step:    121 | Accumulation Step:  13 | Loss:   3.76 | Tokens / Sec:  2840.4 | Learning Rate: 2.8e-04\n",
      "Epoch Step:    161 | Accumulation Step:  17 | Loss:   3.72 | Tokens / Sec:  2829.4 | Learning Rate: 2.9e-04\n",
      "Epoch Step:    201 | Accumulation Step:  21 | Loss:   3.71 | Tokens / Sec:  2834.6 | Learning Rate: 3.0e-04\n",
      "Epoch Step:    241 | Accumulation Step:  25 | Loss:   3.54 | Tokens / Sec:  2832.1 | Learning Rate: 3.1e-04\n",
      "Epoch Step:    281 | Accumulation Step:  29 | Loss:   3.69 | Tokens / Sec:  2863.1 | Learning Rate: 3.2e-04\n",
      "Epoch Step:    321 | Accumulation Step:  33 | Loss:   3.60 | Tokens / Sec:  2858.6 | Learning Rate: 3.3e-04\n",
      "Epoch Step:    361 | Accumulation Step:  37 | Loss:   3.49 | Tokens / Sec:  2809.6 | Learning Rate: 3.4e-04\n",
      "Epoch Step:    401 | Accumulation Step:  41 | Loss:   3.27 | Tokens / Sec:  2835.1 | Learning Rate: 3.5e-04\n",
      "Epoch Step:    441 | Accumulation Step:  45 | Loss:   3.51 | Tokens / Sec:  2826.6 | Learning Rate: 3.6e-04\n",
      "Epoch Step:    481 | Accumulation Step:  49 | Loss:   3.66 | Tokens / Sec:  2857.5 | Learning Rate: 3.7e-04\n",
      "Epoch Step:    521 | Accumulation Step:  53 | Loss:   3.59 | Tokens / Sec:  2843.2 | Learning Rate: 3.8e-04\n",
      "Epoch Step:    561 | Accumulation Step:  57 | Loss:   3.58 | Tokens / Sec:  2862.0 | Learning Rate: 4.0e-04\n",
      "Epoch Step:    601 | Accumulation Step:  61 | Loss:   3.33 | Tokens / Sec:  2813.8 | Learning Rate: 4.1e-04\n",
      "Epoch Step:    641 | Accumulation Step:  65 | Loss:   3.24 | Tokens / Sec:  2820.7 | Learning Rate: 4.2e-04\n",
      "Epoch Step:    681 | Accumulation Step:  69 | Loss:   3.26 | Tokens / Sec:  2833.1 | Learning Rate: 4.3e-04\n",
      "Epoch Step:    721 | Accumulation Step:  73 | Loss:   3.27 | Tokens / Sec:  2848.2 | Learning Rate: 4.4e-04\n",
      "Epoch Step:    761 | Accumulation Step:  77 | Loss:   3.35 | Tokens / Sec:  2919.9 | Learning Rate: 4.5e-04\n",
      "Epoch Step:    801 | Accumulation Step:  81 | Loss:   3.30 | Tokens / Sec:  2824.6 | Learning Rate: 4.6e-04\n",
      "Epoch Step:    841 | Accumulation Step:  85 | Loss:   3.33 | Tokens / Sec:  2835.3 | Learning Rate: 4.7e-04\n",
      "Epoch Step:    881 | Accumulation Step:  89 | Loss:   3.00 | Tokens / Sec:  2868.4 | Learning Rate: 4.8e-04\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 96% | 31% |\n",
      "*****验证*****\n",
      "[GPU0] Epoch 1 Validation ====\n",
      "(tensor(3.0281, device='cuda:0'), <__main__.TrainState object at 0x7f5210239c10>)\n",
      "\n",
      "|   批次: 2   |\n",
      "*****训练*****\n",
      "[GPU0] Epoch 2 Training ====\n",
      "Epoch Step:      1 | Accumulation Step:   1 | Loss:   3.12 | Tokens / Sec:  3347.4 | Learning Rate: 4.9e-04\n",
      "Epoch Step:     41 | Accumulation Step:   5 | Loss:   3.17 | Tokens / Sec:  2842.0 | Learning Rate: 5.0e-04\n",
      "Epoch Step:     81 | Accumulation Step:   9 | Loss:   2.83 | Tokens / Sec:  2841.5 | Learning Rate: 5.1e-04\n",
      "Epoch Step:    121 | Accumulation Step:  13 | Loss:   2.97 | Tokens / Sec:  2813.7 | Learning Rate: 5.2e-04\n",
      "Epoch Step:    161 | Accumulation Step:  17 | Loss:   3.09 | Tokens / Sec:  2836.0 | Learning Rate: 5.3e-04\n",
      "Epoch Step:    201 | Accumulation Step:  21 | Loss:   2.87 | Tokens / Sec:  2836.9 | Learning Rate: 5.4e-04\n",
      "Epoch Step:    241 | Accumulation Step:  25 | Loss:   3.00 | Tokens / Sec:  2856.0 | Learning Rate: 5.5e-04\n",
      "Epoch Step:    281 | Accumulation Step:  29 | Loss:   2.80 | Tokens / Sec:  2797.3 | Learning Rate: 5.6e-04\n",
      "Epoch Step:    321 | Accumulation Step:  33 | Loss:   2.83 | Tokens / Sec:  2764.5 | Learning Rate: 5.7e-04\n",
      "Epoch Step:    361 | Accumulation Step:  37 | Loss:   2.52 | Tokens / Sec:  2831.7 | Learning Rate: 5.9e-04\n",
      "Epoch Step:    401 | Accumulation Step:  41 | Loss:   2.65 | Tokens / Sec:  2867.2 | Learning Rate: 6.0e-04\n",
      "Epoch Step:    441 | Accumulation Step:  45 | Loss:   3.10 | Tokens / Sec:  2860.3 | Learning Rate: 6.1e-04\n",
      "Epoch Step:    481 | Accumulation Step:  49 | Loss:   2.59 | Tokens / Sec:  2856.5 | Learning Rate: 6.2e-04\n",
      "Epoch Step:    521 | Accumulation Step:  53 | Loss:   2.42 | Tokens / Sec:  2844.0 | Learning Rate: 6.3e-04\n",
      "Epoch Step:    561 | Accumulation Step:  57 | Loss:   2.64 | Tokens / Sec:  2860.4 | Learning Rate: 6.4e-04\n",
      "Epoch Step:    601 | Accumulation Step:  61 | Loss:   2.55 | Tokens / Sec:  2839.6 | Learning Rate: 6.5e-04\n",
      "Epoch Step:    641 | Accumulation Step:  65 | Loss:   2.31 | Tokens / Sec:  2820.6 | Learning Rate: 6.6e-04\n",
      "Epoch Step:    681 | Accumulation Step:  69 | Loss:   2.85 | Tokens / Sec:  2846.2 | Learning Rate: 6.7e-04\n",
      "Epoch Step:    721 | Accumulation Step:  73 | Loss:   2.51 | Tokens / Sec:  2790.9 | Learning Rate: 6.8e-04\n",
      "Epoch Step:    761 | Accumulation Step:  77 | Loss:   2.63 | Tokens / Sec:  2865.6 | Learning Rate: 6.9e-04\n",
      "Epoch Step:    801 | Accumulation Step:  81 | Loss:   2.46 | Tokens / Sec:  2855.9 | Learning Rate: 7.0e-04\n",
      "Epoch Step:    841 | Accumulation Step:  85 | Loss:   2.36 | Tokens / Sec:  2858.5 | Learning Rate: 7.1e-04\n",
      "Epoch Step:    881 | Accumulation Step:  89 | Loss:   2.34 | Tokens / Sec:  2878.1 | Learning Rate: 7.3e-04\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 94% | 31% |\n",
      "*****验证*****\n",
      "[GPU0] Epoch 2 Validation ====\n",
      "(tensor(2.3495, device='cuda:0'), <__main__.TrainState object at 0x7f5210239c10>)\n",
      "\n",
      "|   批次: 3   |\n",
      "*****训练*****\n",
      "[GPU0] Epoch 3 Training ====\n",
      "Epoch Step:      1 | Accumulation Step:   1 | Loss:   2.30 | Tokens / Sec:  3084.9 | Learning Rate: 7.3e-04\n",
      "Epoch Step:     41 | Accumulation Step:   5 | Loss:   2.23 | Tokens / Sec:  2816.2 | Learning Rate: 7.4e-04\n",
      "Epoch Step:     81 | Accumulation Step:   9 | Loss:   2.17 | Tokens / Sec:  2853.1 | Learning Rate: 7.5e-04\n",
      "Epoch Step:    121 | Accumulation Step:  13 | Loss:   2.51 | Tokens / Sec:  2814.0 | Learning Rate: 7.6e-04\n",
      "Epoch Step:    161 | Accumulation Step:  17 | Loss:   2.05 | Tokens / Sec:  2822.2 | Learning Rate: 7.8e-04\n",
      "Epoch Step:    201 | Accumulation Step:  21 | Loss:   2.39 | Tokens / Sec:  2845.4 | Learning Rate: 7.9e-04\n",
      "Epoch Step:    241 | Accumulation Step:  25 | Loss:   2.02 | Tokens / Sec:  2748.0 | Learning Rate: 8.0e-04\n",
      "Epoch Step:    281 | Accumulation Step:  29 | Loss:   2.15 | Tokens / Sec:  2846.1 | Learning Rate: 8.1e-04\n",
      "Epoch Step:    321 | Accumulation Step:  33 | Loss:   2.39 | Tokens / Sec:  2839.0 | Learning Rate: 8.0e-04\n",
      "Epoch Step:    361 | Accumulation Step:  37 | Loss:   2.44 | Tokens / Sec:  2849.7 | Learning Rate: 8.0e-04\n",
      "Epoch Step:    401 | Accumulation Step:  41 | Loss:   2.14 | Tokens / Sec:  2886.9 | Learning Rate: 7.9e-04\n",
      "Epoch Step:    441 | Accumulation Step:  45 | Loss:   2.21 | Tokens / Sec:  2809.5 | Learning Rate: 7.9e-04\n",
      "Epoch Step:    481 | Accumulation Step:  49 | Loss:   2.02 | Tokens / Sec:  2825.9 | Learning Rate: 7.8e-04\n",
      "Epoch Step:    521 | Accumulation Step:  53 | Loss:   2.13 | Tokens / Sec:  2807.1 | Learning Rate: 7.8e-04\n",
      "Epoch Step:    561 | Accumulation Step:  57 | Loss:   2.15 | Tokens / Sec:  2858.1 | Learning Rate: 7.7e-04\n",
      "Epoch Step:    601 | Accumulation Step:  61 | Loss:   2.26 | Tokens / Sec:  2897.7 | Learning Rate: 7.7e-04\n",
      "Epoch Step:    641 | Accumulation Step:  65 | Loss:   2.09 | Tokens / Sec:  2811.1 | Learning Rate: 7.6e-04\n",
      "Epoch Step:    681 | Accumulation Step:  69 | Loss:   2.11 | Tokens / Sec:  2850.1 | Learning Rate: 7.6e-04\n",
      "Epoch Step:    721 | Accumulation Step:  73 | Loss:   1.74 | Tokens / Sec:  2820.9 | Learning Rate: 7.5e-04\n",
      "Epoch Step:    761 | Accumulation Step:  77 | Loss:   1.67 | Tokens / Sec:  2812.8 | Learning Rate: 7.5e-04\n",
      "Epoch Step:    801 | Accumulation Step:  81 | Loss:   2.11 | Tokens / Sec:  2807.2 | Learning Rate: 7.4e-04\n",
      "Epoch Step:    841 | Accumulation Step:  85 | Loss:   1.83 | Tokens / Sec:  2790.6 | Learning Rate: 7.4e-04\n",
      "Epoch Step:    881 | Accumulation Step:  89 | Loss:   1.94 | Tokens / Sec:  2851.3 | Learning Rate: 7.4e-04\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 77% | 31% |\n",
      "*****验证*****\n",
      "[GPU0] Epoch 3 Validation ====\n",
      "(tensor(1.9626, device='cuda:0'), <__main__.TrainState object at 0x7f5210239c10>)\n",
      "\n",
      "|   批次: 4   |\n",
      "*****训练*****\n",
      "[GPU0] Epoch 4 Training ====\n",
      "Epoch Step:      1 | Accumulation Step:   1 | Loss:   1.68 | Tokens / Sec:  3411.7 | Learning Rate: 7.3e-04\n",
      "Epoch Step:     41 | Accumulation Step:   5 | Loss:   1.95 | Tokens / Sec:  2865.8 | Learning Rate: 7.3e-04\n",
      "Epoch Step:     81 | Accumulation Step:   9 | Loss:   2.31 | Tokens / Sec:  2848.4 | Learning Rate: 7.3e-04\n",
      "Epoch Step:    121 | Accumulation Step:  13 | Loss:   1.71 | Tokens / Sec:  2763.0 | Learning Rate: 7.2e-04\n",
      "Epoch Step:    161 | Accumulation Step:  17 | Loss:   1.83 | Tokens / Sec:  2876.2 | Learning Rate: 7.2e-04\n",
      "Epoch Step:    201 | Accumulation Step:  21 | Loss:   1.88 | Tokens / Sec:  2803.9 | Learning Rate: 7.1e-04\n",
      "Epoch Step:    241 | Accumulation Step:  25 | Loss:   2.13 | Tokens / Sec:  2840.7 | Learning Rate: 7.1e-04\n",
      "Epoch Step:    281 | Accumulation Step:  29 | Loss:   2.06 | Tokens / Sec:  2822.8 | Learning Rate: 7.1e-04\n",
      "Epoch Step:    321 | Accumulation Step:  33 | Loss:   1.81 | Tokens / Sec:  2836.3 | Learning Rate: 7.0e-04\n",
      "Epoch Step:    361 | Accumulation Step:  37 | Loss:   1.87 | Tokens / Sec:  2812.7 | Learning Rate: 7.0e-04\n",
      "Epoch Step:    401 | Accumulation Step:  41 | Loss:   1.73 | Tokens / Sec:  2837.5 | Learning Rate: 7.0e-04\n",
      "Epoch Step:    441 | Accumulation Step:  45 | Loss:   1.89 | Tokens / Sec:  2845.3 | Learning Rate: 6.9e-04\n",
      "Epoch Step:    481 | Accumulation Step:  49 | Loss:   1.70 | Tokens / Sec:  2877.9 | Learning Rate: 6.9e-04\n",
      "Epoch Step:    521 | Accumulation Step:  53 | Loss:   1.72 | Tokens / Sec:  2895.8 | Learning Rate: 6.9e-04\n",
      "Epoch Step:    561 | Accumulation Step:  57 | Loss:   1.77 | Tokens / Sec:  2857.9 | Learning Rate: 6.8e-04\n",
      "Epoch Step:    601 | Accumulation Step:  61 | Loss:   1.54 | Tokens / Sec:  2865.8 | Learning Rate: 6.8e-04\n",
      "Epoch Step:    641 | Accumulation Step:  65 | Loss:   1.83 | Tokens / Sec:  2871.7 | Learning Rate: 6.8e-04\n",
      "Epoch Step:    681 | Accumulation Step:  69 | Loss:   1.81 | Tokens / Sec:  2807.2 | Learning Rate: 6.7e-04\n",
      "Epoch Step:    721 | Accumulation Step:  73 | Loss:   1.63 | Tokens / Sec:  2810.2 | Learning Rate: 6.7e-04\n",
      "Epoch Step:    761 | Accumulation Step:  77 | Loss:   1.73 | Tokens / Sec:  2835.1 | Learning Rate: 6.7e-04\n",
      "Epoch Step:    801 | Accumulation Step:  81 | Loss:   1.71 | Tokens / Sec:  2815.2 | Learning Rate: 6.6e-04\n",
      "Epoch Step:    841 | Accumulation Step:  85 | Loss:   1.66 | Tokens / Sec:  2856.6 | Learning Rate: 6.6e-04\n",
      "Epoch Step:    881 | Accumulation Step:  89 | Loss:   1.82 | Tokens / Sec:  2804.8 | Learning Rate: 6.6e-04\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 56% | 31% |\n",
      "*****验证*****\n",
      "[GPU0] Epoch 4 Validation ====\n",
      "(tensor(1.7757, device='cuda:0'), <__main__.TrainState object at 0x7f5210239c10>)\n",
      "\n",
      "|   批次: 5   |\n",
      "*****训练*****\n",
      "[GPU0] Epoch 5 Training ====\n",
      "Epoch Step:      1 | Accumulation Step:   1 | Loss:   1.60 | Tokens / Sec:  3143.2 | Learning Rate: 6.6e-04\n",
      "Epoch Step:     41 | Accumulation Step:   5 | Loss:   1.53 | Tokens / Sec:  2836.1 | Learning Rate: 6.5e-04\n",
      "Epoch Step:     81 | Accumulation Step:   9 | Loss:   1.54 | Tokens / Sec:  2812.3 | Learning Rate: 6.5e-04\n",
      "Epoch Step:    121 | Accumulation Step:  13 | Loss:   1.51 | Tokens / Sec:  2814.1 | Learning Rate: 6.5e-04\n",
      "Epoch Step:    161 | Accumulation Step:  17 | Loss:   1.45 | Tokens / Sec:  2879.2 | Learning Rate: 6.4e-04\n",
      "Epoch Step:    201 | Accumulation Step:  21 | Loss:   1.32 | Tokens / Sec:  2810.0 | Learning Rate: 6.4e-04\n",
      "Epoch Step:    241 | Accumulation Step:  25 | Loss:   1.75 | Tokens / Sec:  2841.6 | Learning Rate: 6.4e-04\n",
      "Epoch Step:    281 | Accumulation Step:  29 | Loss:   1.73 | Tokens / Sec:  2814.1 | Learning Rate: 6.4e-04\n",
      "Epoch Step:    321 | Accumulation Step:  33 | Loss:   1.58 | Tokens / Sec:  2830.9 | Learning Rate: 6.3e-04\n",
      "Epoch Step:    361 | Accumulation Step:  37 | Loss:   1.61 | Tokens / Sec:  2851.9 | Learning Rate: 6.3e-04\n",
      "Epoch Step:    401 | Accumulation Step:  41 | Loss:   1.60 | Tokens / Sec:  2881.4 | Learning Rate: 6.3e-04\n",
      "Epoch Step:    441 | Accumulation Step:  45 | Loss:   1.56 | Tokens / Sec:  2823.2 | Learning Rate: 6.3e-04\n",
      "Epoch Step:    481 | Accumulation Step:  49 | Loss:   1.53 | Tokens / Sec:  2832.9 | Learning Rate: 6.2e-04\n",
      "Epoch Step:    521 | Accumulation Step:  53 | Loss:   1.66 | Tokens / Sec:  2760.7 | Learning Rate: 6.2e-04\n",
      "Epoch Step:    561 | Accumulation Step:  57 | Loss:   1.49 | Tokens / Sec:  2892.9 | Learning Rate: 6.2e-04\n",
      "Epoch Step:    601 | Accumulation Step:  61 | Loss:   1.66 | Tokens / Sec:  2824.4 | Learning Rate: 6.2e-04\n",
      "Epoch Step:    641 | Accumulation Step:  65 | Loss:   1.48 | Tokens / Sec:  2848.2 | Learning Rate: 6.1e-04\n",
      "Epoch Step:    681 | Accumulation Step:  69 | Loss:   1.36 | Tokens / Sec:  2923.6 | Learning Rate: 6.1e-04\n",
      "Epoch Step:    721 | Accumulation Step:  73 | Loss:   1.78 | Tokens / Sec:  2841.6 | Learning Rate: 6.1e-04\n",
      "Epoch Step:    761 | Accumulation Step:  77 | Loss:   1.80 | Tokens / Sec:  2870.4 | Learning Rate: 6.1e-04\n",
      "Epoch Step:    801 | Accumulation Step:  81 | Loss:   1.27 | Tokens / Sec:  2821.5 | Learning Rate: 6.0e-04\n",
      "Epoch Step:    841 | Accumulation Step:  85 | Loss:   1.64 | Tokens / Sec:  2842.7 | Learning Rate: 6.0e-04\n",
      "Epoch Step:    881 | Accumulation Step:  89 | Loss:   1.91 | Tokens / Sec:  2810.9 | Learning Rate: 6.0e-04\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 80% | 31% |\n",
      "*****验证*****\n",
      "[GPU0] Epoch 5 Validation ====\n",
      "(tensor(1.6801, device='cuda:0'), <__main__.TrainState object at 0x7f5210239c10>)\n",
      "\n",
      "|   批次: 6   |\n",
      "*****训练*****\n",
      "[GPU0] Epoch 6 Training ====\n",
      "Epoch Step:      1 | Accumulation Step:   1 | Loss:   1.40 | Tokens / Sec:  3227.7 | Learning Rate: 6.0e-04\n",
      "Epoch Step:     41 | Accumulation Step:   5 | Loss:   1.46 | Tokens / Sec:  2857.9 | Learning Rate: 6.0e-04\n",
      "Epoch Step:     81 | Accumulation Step:   9 | Loss:   1.23 | Tokens / Sec:  2870.3 | Learning Rate: 5.9e-04\n",
      "Epoch Step:    121 | Accumulation Step:  13 | Loss:   1.59 | Tokens / Sec:  2834.6 | Learning Rate: 5.9e-04\n",
      "Epoch Step:    161 | Accumulation Step:  17 | Loss:   1.15 | Tokens / Sec:  2845.6 | Learning Rate: 5.9e-04\n",
      "Epoch Step:    201 | Accumulation Step:  21 | Loss:   1.41 | Tokens / Sec:  2828.3 | Learning Rate: 5.9e-04\n",
      "Epoch Step:    241 | Accumulation Step:  25 | Loss:   1.31 | Tokens / Sec:  2811.7 | Learning Rate: 5.9e-04\n",
      "Epoch Step:    281 | Accumulation Step:  29 | Loss:   1.39 | Tokens / Sec:  2831.7 | Learning Rate: 5.8e-04\n",
      "Epoch Step:    321 | Accumulation Step:  33 | Loss:   1.43 | Tokens / Sec:  2791.7 | Learning Rate: 5.8e-04\n",
      "Epoch Step:    361 | Accumulation Step:  37 | Loss:   1.63 | Tokens / Sec:  2846.4 | Learning Rate: 5.8e-04\n",
      "Epoch Step:    401 | Accumulation Step:  41 | Loss:   1.47 | Tokens / Sec:  2814.6 | Learning Rate: 5.8e-04\n",
      "Epoch Step:    441 | Accumulation Step:  45 | Loss:   1.43 | Tokens / Sec:  2863.8 | Learning Rate: 5.8e-04\n",
      "Epoch Step:    481 | Accumulation Step:  49 | Loss:   1.41 | Tokens / Sec:  2812.8 | Learning Rate: 5.7e-04\n",
      "Epoch Step:    521 | Accumulation Step:  53 | Loss:   1.54 | Tokens / Sec:  2895.1 | Learning Rate: 5.7e-04\n",
      "Epoch Step:    561 | Accumulation Step:  57 | Loss:   1.41 | Tokens / Sec:  2882.4 | Learning Rate: 5.7e-04\n",
      "Epoch Step:    601 | Accumulation Step:  61 | Loss:   1.42 | Tokens / Sec:  2862.1 | Learning Rate: 5.7e-04\n",
      "Epoch Step:    641 | Accumulation Step:  65 | Loss:   1.24 | Tokens / Sec:  2855.6 | Learning Rate: 5.7e-04\n",
      "Epoch Step:    681 | Accumulation Step:  69 | Loss:   1.42 | Tokens / Sec:  2819.9 | Learning Rate: 5.6e-04\n",
      "Epoch Step:    721 | Accumulation Step:  73 | Loss:   1.54 | Tokens / Sec:  2858.1 | Learning Rate: 5.6e-04\n",
      "Epoch Step:    761 | Accumulation Step:  77 | Loss:   1.36 | Tokens / Sec:  2826.9 | Learning Rate: 5.6e-04\n",
      "Epoch Step:    801 | Accumulation Step:  81 | Loss:   1.53 | Tokens / Sec:  2887.3 | Learning Rate: 5.6e-04\n",
      "Epoch Step:    841 | Accumulation Step:  85 | Loss:   1.42 | Tokens / Sec:  2822.2 | Learning Rate: 5.6e-04\n",
      "Epoch Step:    881 | Accumulation Step:  89 | Loss:   1.58 | Tokens / Sec:  2849.3 | Learning Rate: 5.6e-04\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 86% | 31% |\n",
      "*****验证*****\n",
      "[GPU0] Epoch 6 Validation ====\n",
      "(tensor(1.6165, device='cuda:0'), <__main__.TrainState object at 0x7f5210239c10>)\n",
      "\n",
      "|   批次: 7   |\n",
      "*****训练*****\n",
      "[GPU0] Epoch 7 Training ====\n",
      "Epoch Step:      1 | Accumulation Step:   1 | Loss:   1.32 | Tokens / Sec:  3409.2 | Learning Rate: 5.5e-04\n",
      "Epoch Step:     41 | Accumulation Step:   5 | Loss:   1.23 | Tokens / Sec:  2816.7 | Learning Rate: 5.5e-04\n",
      "Epoch Step:     81 | Accumulation Step:   9 | Loss:   1.16 | Tokens / Sec:  2844.1 | Learning Rate: 5.5e-04\n",
      "Epoch Step:    121 | Accumulation Step:  13 | Loss:   1.24 | Tokens / Sec:  2860.7 | Learning Rate: 5.5e-04\n",
      "Epoch Step:    161 | Accumulation Step:  17 | Loss:   1.37 | Tokens / Sec:  2799.3 | Learning Rate: 5.5e-04\n",
      "Epoch Step:    201 | Accumulation Step:  21 | Loss:   1.00 | Tokens / Sec:  2854.4 | Learning Rate: 5.5e-04\n",
      "Epoch Step:    241 | Accumulation Step:  25 | Loss:   1.07 | Tokens / Sec:  2834.8 | Learning Rate: 5.4e-04\n",
      "Epoch Step:    281 | Accumulation Step:  29 | Loss:   1.30 | Tokens / Sec:  2894.7 | Learning Rate: 5.4e-04\n",
      "Epoch Step:    321 | Accumulation Step:  33 | Loss:   1.26 | Tokens / Sec:  2872.2 | Learning Rate: 5.4e-04\n",
      "Epoch Step:    361 | Accumulation Step:  37 | Loss:   1.42 | Tokens / Sec:  2817.0 | Learning Rate: 5.4e-04\n",
      "Epoch Step:    401 | Accumulation Step:  41 | Loss:   1.66 | Tokens / Sec:  2831.4 | Learning Rate: 5.4e-04\n",
      "Epoch Step:    441 | Accumulation Step:  45 | Loss:   1.24 | Tokens / Sec:  2844.0 | Learning Rate: 5.4e-04\n",
      "Epoch Step:    481 | Accumulation Step:  49 | Loss:   1.42 | Tokens / Sec:  2882.4 | Learning Rate: 5.3e-04\n",
      "Epoch Step:    521 | Accumulation Step:  53 | Loss:   1.26 | Tokens / Sec:  2819.4 | Learning Rate: 5.3e-04\n",
      "Epoch Step:    561 | Accumulation Step:  57 | Loss:   1.45 | Tokens / Sec:  2894.7 | Learning Rate: 5.3e-04\n",
      "Epoch Step:    601 | Accumulation Step:  61 | Loss:   1.46 | Tokens / Sec:  2809.3 | Learning Rate: 5.3e-04\n",
      "Epoch Step:    641 | Accumulation Step:  65 | Loss:   1.28 | Tokens / Sec:  2855.1 | Learning Rate: 5.3e-04\n",
      "Epoch Step:    681 | Accumulation Step:  69 | Loss:   1.20 | Tokens / Sec:  2846.2 | Learning Rate: 5.3e-04\n",
      "Epoch Step:    721 | Accumulation Step:  73 | Loss:   1.20 | Tokens / Sec:  2832.8 | Learning Rate: 5.3e-04\n",
      "Epoch Step:    761 | Accumulation Step:  77 | Loss:   1.38 | Tokens / Sec:  2888.6 | Learning Rate: 5.2e-04\n",
      "Epoch Step:    801 | Accumulation Step:  81 | Loss:   1.43 | Tokens / Sec:  2803.5 | Learning Rate: 5.2e-04\n",
      "Epoch Step:    841 | Accumulation Step:  85 | Loss:   1.27 | Tokens / Sec:  2835.9 | Learning Rate: 5.2e-04\n",
      "Epoch Step:    881 | Accumulation Step:  89 | Loss:   1.37 | Tokens / Sec:  2793.6 | Learning Rate: 5.2e-04\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 94% | 31% |\n",
      "*****验证*****\n",
      "[GPU0] Epoch 7 Validation ====\n",
      "(tensor(1.5847, device='cuda:0'), <__main__.TrainState object at 0x7f5210239c10>)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    spacy_de, spacy_en = load_tokenizers()\n",
    "    vocab_path = \"./vocab.pt\"\n",
    "    vocab_src, vocab_tgt = load_vocab(spacy_de, spacy_en, vocab_path)\n",
    "    model = load_trained_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08ad1f3",
   "metadata": {
    "papermill": {
     "duration": 0.076626,
     "end_time": "2022-05-16T16:28:09.524845",
     "exception": false,
     "start_time": "2022-05-16T16:28:09.448219",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1281.863644,
   "end_time": "2022-05-16T16:28:12.496663",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-05-16T16:06:50.633019",
   "version": "2.3.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "目录",
   "title_sidebar": "目录",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
