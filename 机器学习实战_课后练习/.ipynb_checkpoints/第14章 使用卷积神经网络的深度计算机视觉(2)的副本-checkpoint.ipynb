{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# 几个用来绘制灰度和 RGB 图像的函数\n",
    "def plot_image(image):\n",
    "    # \"nearest\" 分辨率不匹配时,只显示图像而不尝试在像素之间进行插值\n",
    "    plt.imshow(image, cmap=\"gray\", interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "\n",
    "def plot_color_image(image):\n",
    "    plt.imshow(image, interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "def initialization():\n",
    "    keras.backend.clear_session()\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import font_manager\n",
    "my_font = font_manager.FontProperties(fname='./Fonts/SourceHanSerifSC-Medium.otf', size=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN架构 CNN Architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/other/14-6.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 实现残差结构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  架构形式应用于`18-layer`和`34-layer`:基础残差模块\n",
    "    <img src=\"./images/other/14-37.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# 定义残差模块-基本形式\n",
    "class Residual_Basic(keras.layers.Layer):\n",
    "    expansion = 1  # 扩展系数  -> 默认不使用虚线结构\n",
    "\n",
    "    def __init__(self, out_channel, strides=1, downsample=None, **kwargs):\n",
    "        super(Residual_Basic, self).__init__(**kwargs)\n",
    "        self.conv1 = Conv2D(filters=out_channel,\n",
    "                            kernel_size=3,\n",
    "                            strides=strides,\n",
    "                            padding=\"SAME\",\n",
    "                            use_bias=False)\n",
    "        # 卷积之后，如果要接BN操作，最好是不设置偏置，因为不起作用，\n",
    "        self.bn1 = BatchNormalization(momentum=0.9, epsilon=1e-5)\n",
    "\n",
    "        self.conv2 = Conv2D(filters=out_channel,\n",
    "                            kernel_size=3,\n",
    "                            strides=1,\n",
    "                            padding=\"SAME\",\n",
    "                            use_bias=False)\n",
    "        self.bn2 = BatchNormalization(momentum=0.9, epsilon=1e-5)\n",
    "        # down_sample：使用改变特征图大小核深度的跳过连接\n",
    "        self.downsample = downsample\n",
    "        self.relu = ReLU()\n",
    "        self.add = Add()\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        # 跳过连接分支\n",
    "        skip_Z = inputs\n",
    "\n",
    "        # 使用改变特征图大小核深度的跳过连接分支\n",
    "        if self.downsample is not None:\n",
    "            skip_Z = self.downsample(inputs)\n",
    "\n",
    "        # 主分支\n",
    "        Z = self.conv1(inputs)\n",
    "        Z = self.bn1(Z, training=training)\n",
    "        Z = self.relu(Z)\n",
    "\n",
    "        Z = self.conv2(Z)\n",
    "        Z = self.bn2(Z, training=training)\n",
    "\n",
    "        Z = self.add([Z, skip_Z])\n",
    "        Z = self.relu(Z)\n",
    "\n",
    "        return Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  架构形式应用于`50-layer`,`101-layer`和`152-layer`:使用瓶颈层的残差模块\n",
    "    <img src=\"./images/other/14-38.png\" width=700px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# 定义残差模块-瓶颈层形式\n",
    "class Residual_Bottleneck(keras.layers.Layer):\n",
    "    expansion = 4  # 扩展系数\n",
    "\n",
    "    def __init__(self, out_channel, strides=1, downsample=None, **kwargs):\n",
    "        super(Residual_Bottleneck, self).__init__(**kwargs)\n",
    "        # 1×1卷积核:降低特征维度\n",
    "        self.conv1 = Conv2D(filters=out_channel,\n",
    "                            kernel_size=1,\n",
    "                            use_bias=False,\n",
    "                            name=\"conv1\")\n",
    "        # 名字用于在迁移学习中与预训练模型的层进行匹配\n",
    "        self.bn1 = BatchNormalization(momentum=0.9,\n",
    "                                      epsilon=1e-5,\n",
    "                                      name=\"conv1/BatchNorm\")\n",
    "\n",
    "        self.conv2 = Conv2D(filters=out_channel,\n",
    "                            kernel_size=3,\n",
    "                            strides=strides,\n",
    "                            padding=\"SAME\",\n",
    "                            use_bias=False,\n",
    "                            name=\"conv2\")\n",
    "        self.bn2 = BatchNormalization(momentum=0.9,\n",
    "                                      epsilon=1e-5,\n",
    "                                      name=\"conv2/BatchNorm\")\n",
    "\n",
    "        # 1×1卷积核:升高特征维度\n",
    "        self.conv3 = Conv2D(filters=out_channel * self.expansion,\n",
    "                            # 64->256  128->512  ...\n",
    "                            kernel_size=1,\n",
    "                            use_bias=False,\n",
    "                            name=\"conv3\")\n",
    "        self.bn3 = BatchNormalization(momentum=0.9,\n",
    "                                      epsilon=1e-5,\n",
    "                                      name=\"conv3/BatchNorm\")\n",
    "        # down_sample：使用改变特征图大小核深度的跳过连接\n",
    "        self.downsample = downsample\n",
    "        self.relu = ReLU()\n",
    "        self.add = Add()\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        # 跳过连接分支\n",
    "        skip_Z = inputs\n",
    "\n",
    "        # 使用改变特征图大小核深度的跳过连接分支\n",
    "        if self.downsample is not None:\n",
    "            skip_Z = self.downsample(inputs)\n",
    "\n",
    "        # 主分支\n",
    "        Z = self.conv1(inputs)\n",
    "        Z = self.bn1(Z, training=training)\n",
    "        Z = self.relu(Z)\n",
    "\n",
    "        Z = self.conv2(Z)\n",
    "        Z = self.bn2(Z, training=training)\n",
    "        Z = self.relu(Z)\n",
    "\n",
    "        Z = self.conv3(Z)\n",
    "        Z = self.bn3(Z, training=training)\n",
    "\n",
    "        Z = self.add([Z, skip_Z])\n",
    "        Z = self.relu(Z)\n",
    "\n",
    "        return Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 生成一系列的残差结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_conv_x(block, block_num, in_channel, unit1_channel, name, strides=1):\n",
    "    \"\"\"\n",
    "    :param block: 可选择 Residual_Basic 或 Residual_Bottleneck\n",
    "    :param block_num: 残差结构数量\n",
    "    :param in_channel: 上一层输出特征矩阵的通道数\n",
    "    :param unit1_channel: 本残差模块第一个单元的卷积层的的通道数\n",
    "    \"\"\"\n",
    "    # 使用改变特征图大小核深度的跳过连接分支(虚线结构)\n",
    "    # 1. 当strides大于1时需要：高宽/2,深度加深\n",
    "    # 2. 对于18和34-layer: 第一层不需要虚线结构\n",
    "    # 3. 对于50,101和152-layer: 第一层需要虚线结构：调整特征矩阵的深度，高宽不变.\n",
    "    #                                           ->kernel_size=1\n",
    "    skipLayer = None\n",
    "    out_channel = unit1_channel * block.expansion  # conv3_channel\n",
    "    if (strides != 1) or (in_channel != out_channel):\n",
    "        skipLayer = Sequential([\n",
    "            Conv2D(filters=out_channel, kernel_size=1, strides=strides,\n",
    "                   use_bias=False, name=\"conv1\"),\n",
    "            BatchNormalization(momentum=0.9, epsilon=1.001e-5, name=\"BatchNorm\")\n",
    "        ], name=\"shortcut\")  # 跳过层即捷径层\n",
    "\n",
    "    layersList = []\n",
    "    # 首先针对第一个单元进行处理\n",
    "    layersList.append(block(out_channel=unit1_channel, strides=strides,\n",
    "                            downsample=skipLayer,\n",
    "                            name=\"unit_1\"))\n",
    "    # 然后针对其他单元进行处理\n",
    "    for index in range(1, block_num):  # 3 -> 1, 2\n",
    "        layersList.append(block(out_channel=unit1_channel, strides=1,\n",
    "                                downsample=None,\n",
    "                                name=\"unit_\" + str(index + 1)))\n",
    "\n",
    "    return Sequential(layersList, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为`Conv1`中刚刚对网络输入进行了卷积和最大池化，还没有进行残差学习，此时直接下采样会损失大量信息；而后3个`ConvN_x`直接进行下采样时，前面的网络已经进行过残差学习了，所以可以直接进行下采样。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义ResNet网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet(block,\n",
    "           block_num_list,\n",
    "           height=224,\n",
    "           width=224,\n",
    "           num_classes=1000,\n",
    "           include_top=True):\n",
    "    \"\"\"\n",
    "    :param block: 可选择 Residual_Basic 或 Residual_Bottleneck\n",
    "    :param block_num_list: 残差结构数量 输入为列表\n",
    "    :param height: 输入高度像素\n",
    "    :param width: 输入宽度像素\n",
    "    :param num_classes:  标签的类别数量\n",
    "    :param include_top: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    input = Input(shape=[height, width, 3], dtype=\"float32\")\n",
    "    # ---------------------\n",
    "    Z = Conv2D(filters=64,\n",
    "               kernel_size=7,\n",
    "               strides=2,\n",
    "               padding=\"SAME\",\n",
    "               use_bias=False,\n",
    "               name=\"conv1\")(input)\n",
    "    Z = BatchNormalization(momentum=0.9, epsilon=1e-5,\n",
    "                           name=\"conv1/BatchNorm\")(Z)\n",
    "    Z = ReLU()(Z)\n",
    "\n",
    "    Z = MaxPool2D(pool_size=3, strides=2, padding=\"SAME\")(Z)\n",
    "    # ---------------------\n",
    "    # 每调用一次make_layer()就生成对应`convN_x`的一系列残差结构\n",
    "    # Z.shape对应上一层输出特征矩阵的shape对应[batch, height, weight, channel]\n",
    "    # Z.shape[-1]代表 channel 深度\n",
    "    Z = make_conv_x(block=block,\n",
    "                    block_num=block_num_list[0],\n",
    "                    in_channel=Z.shape[-1],\n",
    "                    unit1_channel=64,\n",
    "                    name=\"block1\")(Z)\n",
    "    Z = make_conv_x(block=block,\n",
    "                    block_num=block_num_list[1],\n",
    "                    in_channel=Z.shape[-1],\n",
    "                    unit1_channel=128,\n",
    "                    name=\"block2\",\n",
    "                    strides=2)(Z)\n",
    "    Z = make_conv_x(block, block_num_list[2], Z.shape[-1], 256, \"block3\", 2)(Z)\n",
    "    Z = make_conv_x(block, block_num_list[3], Z.shape[-1], 512, \"block4\", 2)(Z)\n",
    "    # ---------------------\n",
    "    if include_top:  # 不使用迁移学习\n",
    "        Z = GlobalAvgPool2D()(Z)  # 全局平局池化:结合了pool和flatten的功能\n",
    "        Z = Dense(units=num_classes, name=\"logits\")(Z)\n",
    "        predict = Softmax()(Z)\n",
    "    else:  # 使用迁移学习 可以在后面自定义所需要的层\n",
    "        predict = Z\n",
    "\n",
    "    model = Model(inputs=input, outputs=predict)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义不同的ResNet架构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义ResNet-18\n",
    "def resnet18(height=224, width=224, num_classes=1000, include_top=True):\n",
    "    model = resnet(block=Residual_Basic,\n",
    "                   block_num_list=[2, 2, 2, 2],\n",
    "                   height=height,\n",
    "                   width=width,\n",
    "                   num_classes=num_classes,\n",
    "                   include_top=include_top)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义ResNet-34\n",
    "def resnet34(height=224, width=224, num_classes=1000, include_top=True):\n",
    "    model = resnet(Residual_Basic, [3, 4, 6, 3], height, width, num_classes,\n",
    "                   include_top)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义ResNet-50\n",
    "def resnet50(height=224, width=224, num_classes=1000, include_top=True):\n",
    "    model = resnet(Residual_Bottleneck, [3, 4, 6, 3], height, width,\n",
    "                   num_classes, include_top)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义ResNet-101\n",
    "def resnet101(height=224, width=224, num_classes=1000, include_top=True):\n",
    "    model = resnet(Residual_Bottleneck, [3, 4, 23, 3], height, width,\n",
    "                   num_classes, include_top)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义ResNet-152\n",
    "def resnet152(height=224, width=224, num_classes=1000, include_top=True):\n",
    "    model = resnet(Residual_Bottleneck, [3, 8, 36, 3], height, width,\n",
    "                   num_classes, include_top)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 查看`ResNet-34`模型结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-ef75f0f58eed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet34\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-798e77fbef78>\u001b[0m in \u001b[0;36mresnet34\u001b[0;34m(height, width, num_classes, include_top)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mresnet34\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     model = resnet(Residual_Basic, [3, 4, 6, 3], height, width, num_classes,\n\u001b[0;32m----> 4\u001b[0;31m                    include_top)\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-f724490ee12f>\u001b[0m in \u001b[0;36mresnet\u001b[0;34m(block, block_num_list, height, width, num_classes, include_top)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \"\"\"\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"float32\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;31m# ---------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     Z = Conv2D(filters=64,\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Input' is not defined"
     ]
    }
   ],
   "source": [
    "model = resnet34(num_classes=10)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用迁移学习训练ResNet-50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "dataset, info = tfds.load(\"tf_flowers\", as_supervised=True, with_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info.splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = info.features[\"label\"].names\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = info.features[\"label\"].num_classes\n",
    "n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = info.splits[\"train\"].num_examples\n",
    "dataset_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf_flowers`数据集详细信息:https://tensorflow.google.cn/datasets/catalog/tf_flowers\n",
    "\n",
    "\n",
    "<img src=\"./images/other/14-52.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 拆分数据集\n",
    "\n",
    "    由于该数据集只有一个`train`数据集,没有验证集和测试集,因此需要拆分数据集."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_raw, valid_set_raw, train_set_raw = tfds.load(\n",
    "    \"tf_flowers\",\n",
    "    split=[\"train[:10%]\", \"train[10%:25%]\", \"train[25%:]\"],\n",
    "    as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-30T12:53:38.082318Z",
     "iopub.status.busy": "2021-12-30T12:53:38.081562Z",
     "iopub.status.idle": "2021-12-30T12:54:42.073450Z",
     "shell.execute_reply": "2021-12-30T12:54:42.072532Z",
     "shell.execute_reply.started": "2021-12-30T11:47:25.233643Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 64.010836,
     "end_time": "2021-12-30T12:54:42.073598",
     "exception": false,
     "start_time": "2021-12-30T12:53:38.062762",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "index = 0\n",
    "for image, label in train_set_raw.take(9):\n",
    "    index += 1\n",
    "    plt.subplot(3, 3, index)\n",
    "    plt.imshow(image)\n",
    "    plt.title(\"Class: {}\".format(class_names[label]))\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 图像预处理\n",
    "\n",
    "- 基本预处理:对训练集进行乱序，并为所有数据集添加批处理和预取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "\n",
    "def preprocess(image, label):\n",
    "    resized_image = tf.image.resize(image, [224, 224])\n",
    "    label = tf.cast(label, dtype=tf.int32)\n",
    "    label = tf.squeeze(label)  # tf.squeeze():用于从张量形状中移除大小为1的维度\n",
    "    label = tf.one_hot(label, depth=10)\n",
    "    return resized_image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 进一步预处理:基本预处理的基础上,执行数据增强,即向训练图像添加一些随机变换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 中央裁切\n",
    "def central_crop(image):\n",
    "    shape = tf.shape(image)  # height, width\n",
    "    min_dim = tf.reduce_min([shape[0], shape[1]])\n",
    "\n",
    "    # 从图像左上到右下\n",
    "    top_crop = (shape[0] - min_dim) // 4\n",
    "    bottom_crop = shape[0] - top_crop\n",
    "\n",
    "    left_crop = (shape[1] - min_dim) // 4\n",
    "    right_crop = shape[1] - left_crop\n",
    "\n",
    "    return image[top_crop:bottom_crop, left_crop:right_crop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机裁切\n",
    "def random_crop(image):\n",
    "    shape = tf.shape(image)\n",
    "    min_dim = tf.reduce_min([shape[0], shape[1]]) * 90 // 100\n",
    "\n",
    "    # 如果一个维度不应该被裁剪，则传递该维度的完整大小\n",
    "    cropped_image = tf.image.random_crop(image, size=[min_dim, min_dim, 3])\n",
    "    return cropped_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11995a41",
   "metadata": {
    "papermill": {
     "duration": 0.015056,
     "end_time": "2022-01-07T01:52:34.782774",
     "exception": false,
     "start_time": "2022-01-07T01:52:34.767718",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "如果使用`迁移学习`,需要在图像预处理部分减去`ImageNet`所有图像的均值,即**\\[123.68, 116.78, 103.94\\]** 如果使用别人的预训练模型参数,就必须和別人使用相同的预处理方法!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_R_MEAN = 123.68\n",
    "_G_MEAN = 116.78\n",
    "_B_MEAN = 103.94\n",
    "\n",
    "num_classes = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image, label, randomize=False):\n",
    "    if randomize:\n",
    "        cropped_image = random_crop(image)\n",
    "        # random_flip_left_right:随机水平翻转图像（从左到右）。\n",
    "        cropped_image = tf.image.random_flip_left_right(cropped_image)\n",
    "    else:\n",
    "        cropped_image = central_crop(image)\n",
    "\n",
    "    resized_image = tf.image.resize(image, [224, 224])\n",
    "    final_image = resized_image - [_R_MEAN, _G_MEAN, _B_MEAN]\n",
    "    return final_image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "train_set = train_set_raw.shuffle(1000).repeat()\n",
    "train_set = train_set.map(partial(\n",
    "    preprocess, randomize=True)).batch(batch_size).prefetch(1)\n",
    "\n",
    "valid_set = valid_set_raw.map(preprocess).batch(batch_size).prefetch(1)\n",
    "\n",
    "test_set = test_set_raw.map(preprocess).batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e8d70f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-25T12:00:50.016413Z",
     "iopub.status.busy": "2022-01-25T12:00:50.015839Z",
     "iopub.status.idle": "2022-01-25T12:00:51.827939Z",
     "shell.execute_reply": "2022-01-25T12:00:51.828389Z",
     "shell.execute_reply.started": "2022-01-25T11:56:40.685887Z"
    },
    "papermill": {
     "duration": 1.839893,
     "end_time": "2022-01-25T12:00:51.828556",
     "exception": false,
     "start_time": "2022-01-25T12:00:49.988663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "for X_batch, y_batch in train_set.take(1):\n",
    "    for index in range(9):\n",
    "        plt.subplot(3, 3, index + 1)\n",
    "        plt.imshow(X_batch[index])\n",
    "\n",
    "        plt.title(\"Class: {}\".format(class_names[y_batch[index]]))\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 使用迁移学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = resnet50(num_classes=num_classes, include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载预训练模型的权重\n",
    "pre_weight_path = './PTmodel/tf_resnet50_weights/pretrain_weights.ckpt'\n",
    "feature.load_weights(pre_weight_path)\n",
    "feature.trainable = False  # 冻结预训练模型的权重参数\n",
    "feature.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当我们将 `trainable`设置为 `False`时， `feature`的所有权重都会被冻结，训练过程中也无法在训练这些参数."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型最后面添加全连接层\n",
    "model = Sequential([\n",
    "    feature,\n",
    "    GlobalAvgPool2D(),\n",
    "    Dropout(rate=0.5),\n",
    "    Dense(1024, activation=keras.activations.relu),\n",
    "    Dropout(rate=0.5),\n",
    "    Dense(num_classes),\n",
    "    Softmax()\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a679381e",
   "metadata": {
    "papermill": {
     "duration": 0.027918,
     "end_time": "2022-01-25T12:00:56.371199",
     "exception": false,
     "start_time": "2022-01-25T12:00:56.343281",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "5. 训练,评估模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb63433e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-25T12:00:56.440729Z",
     "iopub.status.busy": "2022-01-25T12:00:56.439721Z",
     "iopub.status.idle": "2022-01-25T12:04:20.939489Z",
     "shell.execute_reply": "2022-01-25T12:04:20.939947Z",
     "shell.execute_reply.started": "2022-01-25T11:56:44.637691Z"
    },
    "papermill": {
     "duration": 204.541114,
     "end_time": "2022-01-25T12:04:20.940161",
     "exception": false,
     "start_time": "2022-01-25T12:00:56.399047",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 编译模型\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "# 训练模型\n",
    "history = model.fit(train_set,\n",
    "                    steps_per_epoch=int(0.75 * dataset_size / batch_size),\n",
    "                    validation_data=valid_set,\n",
    "                    validation_steps=int(0.15 * dataset_size / batch_size),\n",
    "                    epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c85908",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-25T12:04:22.175447Z",
     "iopub.status.busy": "2022-01-25T12:04:22.174579Z",
     "iopub.status.idle": "2022-01-25T12:04:47.188132Z",
     "shell.execute_reply": "2022-01-25T12:04:47.188820Z",
     "shell.execute_reply.started": "2022-01-25T11:57:28.055078Z"
    },
    "papermill": {
     "duration": 25.655828,
     "end_time": "2022-01-25T12:04:47.188999",
     "exception": false,
     "start_time": "2022-01-25T12:04:21.533171",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save(\"my_ResNet50.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe6927a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-25T12:04:48.393493Z",
     "iopub.status.busy": "2022-01-25T12:04:48.391896Z",
     "iopub.status.idle": "2022-01-25T12:04:59.589835Z",
     "shell.execute_reply": "2022-01-25T12:04:59.590871Z",
     "shell.execute_reply.started": "2022-01-25T11:57:51.837078Z"
    },
    "papermill": {
     "duration": 11.812037,
     "end_time": "2022-01-25T12:04:59.591113",
     "exception": false,
     "start_time": "2022-01-25T12:04:47.779076",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"./models/my_ResNet50.ckpt\")\n",
    "model.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e522fadc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-25T12:05:01.139180Z",
     "iopub.status.busy": "2022-01-25T12:05:01.138332Z",
     "iopub.status.idle": "2022-01-25T12:05:01.140530Z",
     "shell.execute_reply": "2022-01-25T12:05:01.141019Z",
     "shell.execute_reply.started": "2022-01-25T11:58:04.698616Z"
    },
    "papermill": {
     "duration": 0.595388,
     "end_time": "2022-01-25T12:05:01.141189",
     "exception": false,
     "start_time": "2022-01-25T12:05:00.545801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "train_loss = history_dict[\"loss\"]\n",
    "train_accuracy = history_dict[\"accuracy\"]\n",
    "val_loss = history_dict[\"val_loss\"]\n",
    "val_accuracy = history_dict[\"val_accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7836c2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-25T12:05:02.455207Z",
     "iopub.status.busy": "2022-01-25T12:05:02.451072Z",
     "iopub.status.idle": "2022-01-25T12:05:02.832401Z",
     "shell.execute_reply": "2022-01-25T12:05:02.832814Z",
     "shell.execute_reply.started": "2022-01-25T11:58:04.705938Z"
    },
    "papermill": {
     "duration": 1.096831,
     "end_time": "2022-01-25T12:05:02.833001",
     "exception": false,
     "start_time": "2022-01-25T12:05:01.736170",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 25\n",
    "# figure 1\n",
    "plt.figure()\n",
    "plt.plot(range(epochs), train_loss, label='train_loss')\n",
    "plt.plot(range(epochs), val_loss, label='val_loss')\n",
    "plt.legend()\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "# figure 2\n",
    "plt.figure()\n",
    "plt.plot(range(epochs), train_accuracy, label='train_accuracy')\n",
    "plt.plot(range(epochs), val_accuracy, label='val_accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用Keras的预训练模型 Using Pretrained Models from Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 获取预训练模型\n",
    "    \n",
    "    通常，您不必手动实现像 `GoogLeNet` 或 `ResNet` 这样的标准模型，因为预训练的网络可以通过 `keras.applications` 包中获得。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个ResNet-50模型并下载ImageNet数据集上预训练的权重\n",
    "model = keras.applications.resnet50.ResNet50(weights=\"imagenet\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_sample_image\n",
    "\n",
    "china = load_sample_image(\"china.jpg\") / 255.0\n",
    "flower = load_sample_image(\"flower.jpg\") / 255.0\n",
    "images = np.array([china, flower])\n",
    "\n",
    "plot_color_image(images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 调整图像的大小\n",
    "\n",
    "    要使用它，首先需要确保图像具有正确的大小。 `ResNet-50` 模型需要 224 × 224 像素的图像.\n",
    "\n",
    "    使用`tf.image.resize()`函数来调整我们之前加载的图像的大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_resized = tf.image.resize(images, [224, 224])\n",
    "plot_color_image(images_resized[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.image.resize() `不保留宽高比,可以使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `tf.image.resize_with_pad()`:调整图像大小并将图像**填充**到目标宽度和高度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_resized = tf.image.resize_with_pad(image=images,\n",
    "                                          target_height=224,\n",
    "                                          target_width=224,\n",
    "                                          antialias=True)  # 抗锯齿\n",
    "plot_color_image(images_resized[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `tf.image.resize_with_crop_or_pad()`:将图像**裁剪**/填充到目标宽度和高度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_resized = tf.image.resize_with_crop_or_pad(image=images,\n",
    "                                                  target_height=224,\n",
    "                                                  target_width=224)\n",
    "plot_color_image(images_resized[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `tf.image.crop_amd_resize()`:同时实现图像裁剪为适当宽高比和调整尺寸的操作.\n",
    "```python\n",
    "tf.image.crop_and_resize(\n",
    "    image,     \n",
    "    boxes,\n",
    "    box_ind,\n",
    "    crop_size,\n",
    "    method='bilinear',\n",
    "    extrapolation_value=0,\n",
    "    name=None\n",
    ")\n",
    "```\n",
    "\n",
    "    1. `image`:一个四维的张量,输入格式为`[batch, image_height, image_width, depth].`\n",
    "    2. `boxes`:指需要划分的区域位置的百分比，输入格式为 `[[ymin,xmin,ymax,xmax]]` ,设crop的区域坐标为 `[ y1,x1,y2,x2 ]`,那么想得到相应正确的crop图形就一定要**归一化**，即图片长度为 [ W,H ],则实际输入的boxes为 [ $\\frac{y_1}{H}$,$\\frac{x_1}{W}$,$\\frac{y_2}{H}$,$\\frac{x_2}{W}$ ]。\n",
    "        - 情况一:不超出1\n",
    "        - 情况二:超出1--自动补齐,当全部超出1，那就是个黑色框了，因为超出1根据归一化截取不到图片任何内容.\n",
    "    3. `box_ind`:用于索引\n",
    "    4. `crop_size`:图像裁剪大小\n",
    "\n",
    "        例:图像高度=427 , 图像宽度=640, 经过标准化后图像($\\frac{427}{255.0}$,$\\frac{640}{255.0}$).框选范围位置的百分比为`[0, 0.03, 1, 0.68]`,\n",
    "            得 [ 0*427=0, 0.03*640=19.2, 1*427=427, 0.68*640=435.2 ],\n",
    "        调整大小到`[224,224]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "china_box = [0, 0.03, 1, 0.68]\n",
    "flower_box = [0.19, 0.26, 0.86, 0.7]\n",
    "\n",
    "images_resized = tf.image.crop_and_resize(image=images,\n",
    "                                          boxes=[china_box, flower_box],\n",
    "                                          box_indices=[0, 1],\n",
    "                                          crop_size=[224, 224])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_color_image(images_resized[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_color_image(images_resized[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 根据预训练模型来预处理图像\n",
    "   \n",
    "   每个模型都提供了一个 `preprocess_input()` 函数，可以使用它来预处理您的图像。**这些函数假定像素值的范围是 0 到 255**，由于之前的工作我们实现了归一化,因此我们必须将它们乘以 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.applications.resnet50.preprocess_input(images_resized * 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 预测\n",
    "    \n",
    "    输出 `y_proba` 是一个矩阵，每幅图像一行，每类一列。\n",
    "    \n",
    "    如果要显示前 K 个预测(包括类名和每个预测类的估计概率)使用 `decode_predictions()`。对于每个图像，它返回一个包含前 K 个预测的数组，其中每个预测都表示为一个**包含类标识符**（在 `ImageNet` 数据集中，每个图像都与 `WordNet `数据集中的一个词相关联：类ID是一个`WordNetID`）,它的名称，以及相应的置信度分数的数组."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = model.predict(inputs)\n",
    "np.shape(y_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_K = keras.applications.resnet50.decode_predictions(y_proba, top=3)\n",
    "\n",
    "for image_index in range(len(images)):  # 0,1\n",
    "    print(\"Image #{}\".format(image_index))\n",
    "    for class_id, name, y_proba in top_K[image_index]:\n",
    "        print(\"  {} - {:12s} {:.2f}%\".format(class_id, name, y_proba * 100))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Apotosome 01/25/22"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "285px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
